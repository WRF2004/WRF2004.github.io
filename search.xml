<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>BUAA-OS-lab5</title>
      <link href="/2024/05/12/BUAA-OS-lab5/"/>
      <url>/2024/05/12/BUAA-OS-lab5/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OS-Lab5"><a href="#BUAA-OS-Lab5" class="headerlink" title="BUAA-OS-Lab5"></a>BUAA-OS-Lab5</h3><h4 id="一、思考题"><a href="#一、思考题" class="headerlink" title="一、思考题"></a>一、思考题</h4><h5 id="Thinking-5-1"><a href="#Thinking-5-1" class="headerlink" title="Thinking 5.1"></a>Thinking 5.1</h5><blockquote><p> 如果通过 kseg0 读写设备，那么对于设备的写入会缓存到 Cache 中。这是 一种错误的行为，在实际编写代码的时候这么做会引发不可预知的问题。请思考：这么做 这会引发什么问题？对于不同种类的设备（如我们提到的串口设备和IDE磁盘）的操作会 有差异吗？可以从缓存的性质和缓存更新的策略来考虑。</p></blockquote><p>缓存机制是为了提高效率而设计的，具体体现为数据发生改变时并不立即写入内存，而是在cache发生替换时才写入。可能会导致数据不一致，如果对设备的写操作被缓存，那么后续读操作可能会从缓存中读取旧数据，而不是设备上的最新数据。</p><p>有差异，串口设备要求较高的实时性，如果写操作被缓存，可能导致数据发送延迟，影响系统正常运行；IDE磁盘数据即时性的要求不高，但错误的缓存行为可能导致文件系统损坏或数据丢失。</p><h5 id="Thinking-5-2"><a href="#Thinking-5-2" class="headerlink" title="Thinking 5.2"></a>Thinking 5.2</h5><blockquote><p>查找代码中的相关定义，试回答一个磁盘块中最多能存储多少个文件控制 块？一个目录下最多能有多少个文件？我们的文件系统支持的单个文件最大为多大？</p></blockquote><p>一个磁盘块中最多能存储16个文件控制块，一个目录最多有16384个文件，单个文件最大为4MB。</p><h5 id="Thinking-5-3"><a href="#Thinking-5-3" class="headerlink" title="Thinking 5.3"></a>Thinking 5.3</h5><blockquote><p>请思考，在满足磁盘块缓存的设计的前提下，我们实验使用的内核支持的最 大磁盘大小是多少？</p></blockquote><p>1GB</p><h5 id="Thinking-5-4"><a href="#Thinking-5-4" class="headerlink" title="Thinking 5.4"></a>Thinking 5.4</h5><blockquote><p>在本实验中，fs&#x2F;serv.h、user&#x2F;include&#x2F;fs.h 等文件中出现了许多宏定义， 试列举你认为较为重要的宏定义，同时进行解释，并描述其主要应用之处。</p></blockquote><blockquote><p>#define SECT_SIZE 512  扇区大小512字节</p><p>#define SECT2BLK (BLOCK_SIZE &#x2F; SECT_SIZE)  1 个磁盘块是 8 个扇区#define DISKMAP 0x10000000</p><p>#define DISKMAX 0x40000000 缓冲区地址0x10000000-0x40000000</p><p>#define BLOCK_SIZE PAGE_SIZE 一个磁盘块大小为4KB</p><p>#define FILE_STRUCT_SIZE 256 文件控制块大小256字节</p><p>#define FILE2BLK (BLOCK_SIZE &#x2F; sizeof(struct File)) 1个磁盘块有16个文件控制块</p><p>#define MAXNAMELEN 128 最大文件名长度为128</p></blockquote><h5 id="Thinking-5-5"><a href="#Thinking-5-5" class="headerlink" title="Thinking 5.5"></a>Thinking 5.5</h5><blockquote><p>在Lab4“系统调用与fork”的实验中我们实现了极为重要的fork函数。那 么fork前后的父子进程是否会共享文件描述符和定位指针呢？请在完成上述练习的基础上 编写一个程序进行验证。</p></blockquote><p>会共享文件描述符和定位指针。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">int r, fdnum, n;</span><br><span class="line">char buf[200];</span><br><span class="line">fdnum &#x3D; open(&quot;&#x2F;newmotd&quot;, O_RDWR);</span><br><span class="line">if ((r &#x3D; fork()) &#x3D;&#x3D; 0) &#123;</span><br><span class="line">n &#x3D; read(fdnum, buf, 5);</span><br><span class="line">printk(&quot;[child] buffer is \&#39;%s\&#39;\n&quot;, buf);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">n &#x3D; read(fdnum, buf, 5);</span><br><span class="line">printk(&quot;[father] buffer is \&#39;%s\&#39;\n&quot;, buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="Thinking-5-6"><a href="#Thinking-5-6" class="headerlink" title="Thinking 5.6"></a>Thinking 5.6</h5><blockquote><p>请解释File, Fd, Filefd结构体及其各个域的作用。比如各个结构体会在哪些过程中被使用，是否对应磁盘上的物理实体还是单纯的内存数据等。说明形式自定，要求简洁明了，可大致勾勒出文件系统数据结构与物理实体的对应关系与设计框架。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct Fd &#123; &#x2F;&#x2F; 文件描述符，该结构体用于管理文件描述符，存储相应数据</span><br><span class="line">u_int fd_dev_id; &#x2F;&#x2F;  设备id</span><br><span class="line">u_int fd_offset; &#x2F;&#x2F; 偏移量，类似于文件定位指针，标记随机读写的位置</span><br><span class="line">u_int fd_omode; &#x2F;&#x2F; 用户对该文件的操作权限和方式</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct Filefd &#123; &#x2F;&#x2F; 已经打开的文件的文件描述符， 相较于Fd，有文件控制块f_file和fileid</span><br><span class="line">struct Fd f_fd; &#x2F;&#x2F; 文件描述符，记录打开文件的部分信息</span><br><span class="line">u_int f_fileid; &#x2F;&#x2F; 打开的文件的编号</span><br><span class="line">struct File f_file; &#x2F;&#x2F; 文件控制块</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">struct File &#123; &#x2F;&#x2F; 文件控制块，包含文件的基本信息</span><br><span class="line">char f_name[MAXNAMELEN]; &#x2F;&#x2F; filename文件名</span><br><span class="line">uint32_t f_size; &#x2F;&#x2F; file size in bytes文件大小</span><br><span class="line">uint32_t f_type; &#x2F;&#x2F; file type文件类型</span><br><span class="line">uint32_t f_direct[NDIRECT]; &#x2F;&#x2F; 文件的直接指针，每个文件</span><br><span class="line">控制块设有10个直接指针，用来记录文件的数据块在磁盘上的位置。</span><br><span class="line">uint32_t f_indirect; &#x2F;&#x2F; 指向一个间接磁盘块，用来存储指向文件内容的磁盘块的指针。</span><br><span class="line"></span><br><span class="line">struct File *f_dir; &#x2F;&#x2F; the pointer to the dir where this file is in, valid only in memory. 指向这个文件所在目录的指针</span><br><span class="line">char f_pad[FILE_STRUCT_SIZE - MAXNAMELEN - (3 + NDIRECT) * 4 - sizeof(void *)]; &#x2F;&#x2F; 为了让整数个文件结构体占用一个磁盘块，填充结构体中剩下的字节。</span><br><span class="line">&#125; __attribute__((aligned(4), packed));</span><br></pre></td></tr></table></figure><h5 id="Thinking-5-7"><a href="#Thinking-5-7" class="headerlink" title="Thinking 5.7"></a>Thinking 5.7</h5><blockquote><p>图 5.9 中有多种不同形式的箭头，请解释这些不同箭头的差别，并思考我们的操作系统是如何实现对应类型的进程间通信的。</p></blockquote><p><img src="/2024-05-12-BUAA-OS-lab5/1.png"></p><p>ENV_CREATE(user_env)箭头：init&#x2F;中创建用户进程，进程在user&#x2F;中运行。</p><p>ENV_CREATE(fs_serv)箭头：init&#x2F;中创建文件系统进程，进程在fs&#x2F;中运行。</p><p>ipc_send(fsreq)箭头：用户进程执行打开文件操作，通过ipc将请AAA求发送给文件系统进程。</p><p>ipc_send(dst_va)箭头：文件系统进程收到请求后处理之后，向用户进程发送结果。</p><p>我们的操作系统是通过系统调用，将源地址的数据传输到目标地址中从而实现进程间的通信。</p><h4 id="二、实验难点"><a href="#二、实验难点" class="headerlink" title="二、实验难点"></a>二、实验难点</h4><h5 id="难点1：理解目录、文件、磁盘块以及索引节点的关系"><a href="#难点1：理解目录、文件、磁盘块以及索引节点的关系" class="headerlink" title="难点1：理解目录、文件、磁盘块以及索引节点的关系"></a>难点1：理解目录、文件、磁盘块以及索引节点的关系</h5><p><img src="/2024-05-12-BUAA-OS-lab5/2.png"></p><ul><li>目录是文件，文件目录是目录</li><li>文件中的数据保存在磁盘块中，可以通过直接索引获得文件信息，如果文件较大，则通过间接索引指向目录，再通过目录获得更多磁盘块用于存储文件信息。</li></ul><h5 id="难点2：理解文件系统服务进程如何服务用户进程"><a href="#难点2：理解文件系统服务进程如何服务用户进程" class="headerlink" title="难点2：理解文件系统服务进程如何服务用户进程"></a>难点2：理解文件系统服务进程如何服务用户进程</h5><p><img src="/2024-05-12-BUAA-OS-lab5/3.png"></p><p>用户进程需要通过进程间通信请求文件系统服务，将请求的内容放在对应的结构体中进行消息的传递， fs_serv 进程收到其他进行的 IPC 请求后，IPC 传递的消息包含了请求的类型和其他必要的参 数，根据请求的类型执行相应的文件操作（文件的增、删、改、查等），将结果重新通过IPC反 馈给用户程序。</p><h5 id="三、实验体会"><a href="#三、实验体会" class="headerlink" title="三、实验体会"></a>三、实验体会</h5><p>在lab5我们实现了文件系统的构建，了解文件系统的基本概念和作用，掌握并实现文件系统服务的基本操作，其中运用的类似于面向对象中的继承和接口设计，底层向上层暴露封装好的接口，掩盖掉实现的细节的思想在我们后续的学习过程中有很大的意义，值得我们认真学习。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LLM_Learning</title>
      <link href="/2024/04/25/LLM-Learning/"/>
      <url>/2024/04/25/LLM-Learning/</url>
      
        <content type="html"><![CDATA[<h3 id="大模型"><a href="#大模型" class="headerlink" title="大模型"></a>大模型</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><strong>大模型是指具有大规模参数和复杂计算结构的机器学习模型。</strong>这些模型通常由<strong>深度神经网络</strong>构建而成，拥有数十亿甚至数千亿个参数。大模型的设计目的是为了提高模型的表达能力和预测性能，能够处理更加复杂的任务和数据。大模型在各种领域都有广泛的应用，包括自然语言处理、计算机视觉、语音识别和推荐系统等。大模型通过训练海量数据来学习复杂的模式和特征，具有更强大的泛化能力，可以对未见过的数据做出准确的预测。</p><p><strong>大模型与小模型的区别</strong>: 当模型的训练数据和参数不断扩大，直到达到一定的临界规模后，其表现出了一些未能预测的、更复杂的能力和特性，模型能够从原始训练数据中自动学习并发现新的、更高层次的特征和模式，这种能力被称为<strong>涌现能力</strong>。而具备涌现能力的机器学习模型就被认为是独立意义上的大模型，这也是其和小模型最大意义上的区别。</p><h4 id="大模型相关概念区分"><a href="#大模型相关概念区分" class="headerlink" title="大模型相关概念区分"></a>大模型相关概念区分</h4><ul><li><strong>大模型（Large Model,也称基础模型，即 Foundation Model），</strong>是指具有大量参数和复杂结构的机器学习模型，能够处理海量数据、完成各种复杂的任务，如自然语言处理、计算机视觉、语音识别等。</li><li><strong>超大模型：</strong>大模型是超大模型的一个子集，它们的参数量远超过大模型。</li><li><strong>大语言模型(Large Language Model):</strong> 通常是具有大规模参数和计算能力的自然语言处理模型，例如 OpenAI 的 GPT-3 模型。这些模型可以通过大量的数据和参数进行训练，以<strong>生成人类类似的文本或回答自然语言的问题</strong>。大型语言模型在自然语言处理、文本生成和智能对话等领域有广泛应用。</li><li><strong>GPT（Generative Pre-trained Transformer）：</strong>GPT 和 ChatGPT 都是基于 Transformer 架构的语言模型，但它们在设计和应用上存在区别：GPT 模型旨在生成自然语言文本并处理各种自然语言处理任务，如文本生成、翻译、摘要等。它通常在单向生成的情况下使用，即根据给定的文本生成连贯的输出。</li><li><strong>ChatGPT：</strong>ChatGPT 则专注于对话和交互式对话。它经过特定的训练，以更好地处理多轮对话和上下文理解。ChatGPT 设计用于提供流畅、连贯和有趣的对话体验，以响应用户的输入并生成合适的回复。</li></ul><h4 id="大模型的发展历程"><a href="#大模型的发展历程" class="headerlink" title="大模型的发展历程"></a>大模型的发展历程</h4><p><strong>萌芽期（1950-2005）：以 CNN 为代表的传统神经网络模型阶段</strong></p><ul><li>1956 年，从计算机专家约翰·麦卡锡提出“人工智能”概念开始，AI 发展由最开始基于小规模专家知识逐步发展为基于机器学习。</li><li>1980 年，卷积神经网络的雏形 CNN 诞生。</li><li>1998 年，现代卷积神经网络的基本结构 LeNet-5 诞生，机器学习方法由早期基于浅层机器学习的模型，变为了基于深度学习的模型,为自然语言生成、计算机视觉等领域的深入研究奠定了基础，对后续深度学习框架的迭代及大模型发展具有开创性的意义。</li></ul><p><strong>探索沉淀期（2006-2019）：以 Transformer 为代表的全新神经网络模型阶段</strong></p><ul><li>2013 年，自然语言处理模型 Word2Vec 诞生，首次提出将单词转换为向量的“词向量模型”，以便计算机更好地理解和处理文本数据。</li><li>2014 年，被誉为 21 世纪最强大算法模型之一的 GAN（对抗式生成网络）诞生，标志着深度学习进入了生成模型研究的新阶段。</li><li>2017 年，Google 颠覆性地提出了基于自注意力机制的神经网络结构——Transformer 架构，奠定了大模型预训练算法架构的基础。</li><li>2018 年，OpenAI 和 Google 分别发布了 GPT-1 与 BERT 大模型，意味着预训练大模型成为自然语言处理领域的主流。在探索期，以 Transformer 为代表的全新神经网络架构，奠定了大模型的算法架构基础，使大模型技术的性能得到了显著提升。</li></ul><p><strong>迅猛发展期（2020-至今）：以 GPT 为代表的预训练大模型阶段</strong></p><ul><li>2020 年，OpenAI 公司推出了GPT-3，模型参数规模达到了 1750 亿，成为当时最大的语言模型，并且在零样本学习任务上实现了巨大性能提升。随后，更多策略如基于人类反馈的强化学习（RHLF）、代码预训练、指令微调等开始出现, 被用于进一步提高推理能力和任务泛化。</li><li>2022 年 11 月，搭载了GPT3.5的 ChatGPT横空出世，凭借逼真的自然语言交互与多场景内容生成能力，迅速引爆互联网。</li><li>2023 年 3 月，最新发布的超大规模多模态预训练大模型——GPT-4，具备了多模态理解与多类型内容生成能力。在迅猛发展期，大数据、大算力和大算法完美结合，大幅提升了大模型的预训练和生成能力以及多模态多场景应用能力。如 ChatGPT 的巨大成功,就是在微软Azure强大的算力以及 wiki 等海量数据支持下，在 Transformer 架构基础上，坚持 GPT 模型及人类反馈的强化学习（RLHF）进行精调的策略下取得的。</li></ul><h4 id="大模型的特点"><a href="#大模型的特点" class="headerlink" title="大模型的特点"></a>大模型的特点</h4><ul><li>巨大的规模: 大模型包含数十亿个参数，模型大小可以达到数百 GB 甚至更大。巨大的模型规模使大模型具有强大的表达能力和学习能力。</li><li>涌现能力：涌现（英语：emergence）或称创发、突现、呈展、演生，是一种现象，为许多小实体相互作用后产生了大实体，而这个大实体展现了组成它的小实体所不具有的特性。引申到模型层面，涌现能力指的是当模型的训练数据突破一定规模，模型突然涌现出之前小模型所没有的、意料之外的、能够综合分析和解决更深层次问题的复杂能力和特性，展现出类似人类的思维和智能。涌现能力也是大模型最显著的特点之一。</li><li>更好的性能和泛化能力： 大模型通常具有更强大的学习能力和泛化能力，能够在各种任务上表现出色，包括自然语言处理、图像识别、语音识别等。</li><li>多任务学习: 大模型通常会一起学习多种不同的 NLP 任务,如机器翻译、文本摘要、问答系统等。这可以使模型学习到更广泛和泛化的语言理解能力。</li><li>大数据训练: 大模型需要海量的数据来训练,通常在 TB 以上甚至 PB 级别的数据集。只有大量的数据才能发挥大模型的参数规模优势。</li><li>强大的计算资源: 训练大模型通常需要数百甚至上千个 GPU,以及大量的时间,通常在几周到几个月。</li><li>迁移学习和预训练： 大模型可以通过在大规模数据上进行预训练，然后在特定任务上进行微调，从而提高模型在新任务上的性能。</li><li>自监督学习： 大模型可以通过自监督学习在大规模未标记数据上进行训练，从而减少对标记数据的依赖，提高模型的效能。</li></ul><h4 id="大模型的分类"><a href="#大模型的分类" class="headerlink" title="大模型的分类"></a>大模型的分类</h4><p>按照<strong>输入数据类型</strong>的不同，大模型主要可以分为以下三大类：</p><ul><li>语言大模型（NLP）：是指在自然语言处理（Natural Language Processing，NLP）领域中的一类大模型，通常用于处理文本数据和理解自然语言。这类大模型的主要特点是它们在大规模语料库上进行了训练，以学习自然语言的各种语法、语义和语境规则。例如：GPT 系列（OpenAI）、Bard（Google）、文心一言（百度）。</li><li>视觉大模型（CV）：是指在计算机视觉（Computer Vision，CV）领域中使用的大模型，通常用于图像处理和分析。这类模型通过在大规模图像数据上进行训练，可以实现各种视觉任务，如图像分类、目标检测、图像分割、姿态估计、人脸识别等。例如：VIT 系列（Google）、文心UFO、华为盘古 CV、INTERN（商汤）。</li><li>多模态大模型：是指能够处理多种不同类型数据的大模型，例如文本、图像、音频等多模态数据。这类模型结合了 NLP 和 CV 的能力，以实现对多模态信息的综合理解和分析，从而能够更全面地理解和处理复杂的数据。例如：DingoDB 多模向量数据库（九章云极 DataCanvas）、DALL-E(OpenAI)、悟空画画（华为）、midjourney。</li></ul><p>按照<strong>应用领域</strong>的不同，大模型主要可以分为 L0、L1、L2 三个层级：</p><ul><li>通用大模型 L0：是指可以在多个领域和任务上通用的大模型。它们利用大算力、使用海量的开放数据与具有巨量参数的深度学习算法，在大规模无标注数据上进行训练，以寻找特征并发现规律，进而形成可“举一反三”的强大泛化能力，可在不进行微调或少量微调的情况下完成多场景任务，相当于 AI 完成了“通识教育”。</li><li>行业大模型 L1：是指那些针对特定行业或领域的大模型。它们通常使用行业相关的数据进行预训练或微调，以提高在该领域的性能和准确度，相当于 AI 成为“行业专家”。</li><li>垂直大模型 L2：是指那些针对特定任务或场景的大模型。它们通常使用任务相关的数据进行预训练或微调，以提高在该任务上的性能和效果。</li></ul><h4 id="大模型的泛化与微调"><a href="#大模型的泛化与微调" class="headerlink" title="大模型的泛化与微调"></a>大模型的泛化与微调</h4><p><strong>模型的泛化能力</strong>：是指一个模型在面对新的、未见过的数据时，能够正确理解和预测这些数据的能力。在机器学习和人工智能领域，模型的泛化能力是评估模型性能的重要指标之一。</p><p>什么是<strong>模型微调</strong>：给定预训练模型（Pre-trained model），基于模型进行微调（Fine Tune）。相对于从头开始训练(Training a model from scatch)，微调可以省去大量计算资源和计算时间，提高计算效率,甚至提高准确率。</p><p><strong>模型微调的基本思想是使用少量带标签的数据对预训练模型进行再次训练，以适应特定任务。</strong>在这个过程中，模型的参数会根据新的数据分布进行调整。这种方法的好处在于，它利用了预训练模型的强大能力，同时还能够适应新的数据分布。因此，模型微调能够提高模型的泛化能力，减少过拟合现象。</p><p><strong>常见的模型微调方法：</strong></p><ul><li>Fine-tuning：这是最常用的微调方法。通过在预训练模型的最后一层添加一个新的分类层，然后根据新的数据集进行微调。</li><li>Feature augmentation：这种方法通过向数据中添加一些人工特征来增强模型的性能。这些特征可以是手工设计的，也可以是通过自动特征生成技术生成的。</li><li>Transfer learning：这种方法是使用在一个任务上训练过的模型作为新任务的起点，然后对模型的参数进行微调，以适应新的任务。</li></ul><h4 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h4><p>Transformer是一种基于自注意力机制（Self-Attention Mechanism）的深度学习模型架构，最初是为了解决自然语言处理（NLP）任务中的序列到序列（Sequence-to-Sequence）学习问题而提出的。它由谷歌的研究人员在2017年的论文“Attention is All You Need”中首次介绍，并在之后的许多NLP任务中取得了显著的效果。</p><p>Transformer主要由两部分组成：编码器（Encoder）和解码器（Decoder）。每个编码器和解码器都包含多个堆叠的相同层。</p><p><strong>编码器</strong>：</p><ul><li>编码器主要由自注意力层和前馈神经网络层组成。</li><li>自注意力层允许模型在处理序列中的每个位置时，都考虑到序列中的其他所有位置。这通过计算输入序列中每个位置的表示（通常称为“token embeddings”）之间的点积得分，并应用softmax函数得到注意力权重来实现。</li><li>前馈神经网络层则对每个位置的注意力加权表示进行进一步处理。</li></ul><p><strong>解码器</strong>：</p><ul><li>解码器也有自注意力层和前馈神经网络层，但与编码器不同的是，解码器还有一个额外的编码器-解码器注意力层。</li><li>编码器-解码器注意力层允许解码器在生成输出序列时，关注编码器的输出。这使得模型能够考虑到整个输入序列的信息来预测下一个输出。</li></ul><p>Transformer还采用了位置编码（Positional Encoding）机制，以弥补模型本身无法处理序列顺序信息的缺陷。位置编码通常是通过正弦和余弦函数计算得到的，并加到输入嵌入中。</p><p>由于Transformer的并行计算能力（不依赖RNN的逐序处理）以及自注意力机制带来的强大表示能力，它成为了许多NLP任务中的首选模型架构，特别是在机器翻译、文本摘要、问答系统等领域取得了显著成果。此外，Transformer的思想也被扩展到了其他领域，如计算机视觉等。</p><h4 id="Decoder-only的自回归解码"><a href="#Decoder-only的自回归解码" class="headerlink" title="Decoder-only的自回归解码"></a>Decoder-only的自回归解码</h4><p>Decoder-Only的自回归解码是Transformer模型中的一种特定结构和方法。在这种结构中，解码器（Decoder）部分被独立出来，用于生成目标序列，而不需要使用编码器（Encoder）来处理输入序列。这种模型架构的设计使得Decoder-Only在处理生成式任务时具有一定的优势。</p><p>自回归性质是Decoder-Only技术的一个核心特点。在生成输出序列时，每个位置的预测都依赖于之前位置的预测结果。具体来说，解码器只能看到已生成的部分序列，而不能看到未生成部分的信息。这种因果关系的设计使得Decoder-Only技术在生成式任务中能够更好地捕捉上下文信息，并生成具有逻辑和语法结构的输出。</p><p>这种自回归解码的过程逐步进行，使得模型能够灵活地应对长度不固定的输入序列。在每个步骤中，解码器根据已经生成的序列部分和可能的上下文信息来预测下一个词或符号。这种逐步生成的方式使得Decoder-Only模型在翻译、摘要生成、问答系统等多个领域取得了令人瞩目的成果。</p><p>值得注意的是，尽管Decoder-Only模型在生成式任务中表现出色，但它并不适用于所有类型的任务。对于需要同时考虑输入和输出信息的任务，完整的Transformer编码器-解码器结构可能更为合适。因此，在选择使用Decoder-Only模型时，需要根据具体任务的需求和特性进行权衡。</p><h3 id="量化"><a href="#量化" class="headerlink" title="量化"></a>量化</h3><h4 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h4><p><strong>在大模型领域中，量化是一种重要的技术。主要用于减少模型的存储空间和计算量，同时保持模型的性能。</strong></p><p>具体来说，<strong>量化是指将预训练模型中的权重从浮点数转换成低位数的技术，通常情况下，量化的精度是8位或更低。</strong></p><h4 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h4><p>量化可以分为不同的类型，例如<strong>对称量化</strong>和<strong>非对称量化</strong>。</p><p>在对称量化中，浮点值的零点直接映射到量化值的零点，与量化相关的参数只有缩放因子s。而非对称量化可能需要更多的参数来调整零点的映射位置。</p><p>此外，根据量化的粒度，还可以分为通道量化、逐组量化、逐层量化和组合量化。通道量化、逐组量化和逐层量化分别以单一通道、组、层为单位计算对应float变量范围进行量化，而组合量化则是对多个神经网络结构进行融合后进行量化。</p><p>在大模型领域中，量化技术通常与训练过程相结合，形成量化感知训练（Quantization Aware Training, QAT）和量化感知微调（Quantization-Aware Fine-tuning, QAF）。这些方法旨在在模型压缩和保持性能之间取得平衡，使模型在量化后仍能保持良好的性能。</p><p>总的来说，大模型领域的量化是一种重要的优化技术，有助于减少模型的存储和计算成本，同时保持模型的性能，使得大型语言模型更易于部署和应用。</p>]]></content>
      
      
      
        <tags>
            
            <tag> LLML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OS-Lab4</title>
      <link href="/2024/04/22/BUAA-OS-Lab4/"/>
      <url>/2024/04/22/BUAA-OS-Lab4/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OS-Lab4"><a href="#BUAA-OS-Lab4" class="headerlink" title="BUAA-OS-Lab4"></a>BUAA-OS-Lab4</h3><h4 id="一、思考题"><a href="#一、思考题" class="headerlink" title="一、思考题"></a>一、思考题</h4><h5 id="Thinking-4-1"><a href="#Thinking-4-1" class="headerlink" title="Thinking 4.1"></a>Thinking 4.1</h5><blockquote><p>思考并回答下面的问题： </p><p>•内核在保存现场的时候是如何避免破坏通用寄存器的？</p><p>•系统陷入内核调用后可以直接从当时的$a0-$a3参数寄存器中得到用户调用msyscall 留下的信息吗？ </p><p>•我们是怎么做到让sys开头的函数“认为”我们提供了和用户调用msyscall时同样 的参数的？</p><p>•内核处理系统调用的过程对Trapframe做了哪些更改？这种修改对应的用户态的变 化是什么？</p></blockquote><p>1、</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mfc0    k0, CP0_STATUS</span><br><span class="line">sw      k0, TF_STATUS(sp)</span><br></pre></td></tr></table></figure><p>先把通用寄存器的值复制到k0中，再将k0中的值存储到内核栈中。</p><p>2、可以。</p><p>3、将参数复制到内核现场寄存器和内核栈中。</p><p>4、返回值存入$v0中，pc+4跳转到下一条指令。若是nop则pc不变。</p><h5 id="Thinking-4-2"><a href="#Thinking-4-2" class="headerlink" title="Thinking 4.2"></a>Thinking 4.2</h5><blockquote><p>思考 envid2env函数: 为什么 envid2env中需要判断 e-&gt;env_id != envid 的情况？如果没有这步判断会发生什么情况？</p></blockquote><p>因为使用envid从envs中取出的进程的env_id可能与envid不同，如果没有这步判断会导致进程出错。</p><h5 id="Thinking-4-3"><a href="#Thinking-4-3" class="headerlink" title="Thinking 4.3"></a>Thinking 4.3</h5><blockquote><p> 思考下面的问题，并对这个问题谈谈你的理解：请回顾 kern/env.c 文件 中 mkenvid() 函数的实现，该函数不会返回 0，请结合系统调用和 IPC 部分的实现与 envid2env() 函数的行为进行解释。</p></blockquote><p>在mkenvid() 函数中i一开始为0，++i后使得其返回值不为0。</p><h5 id="Thinking-4-4"><a href="#Thinking-4-4" class="headerlink" title="Thinking 4.4"></a>Thinking 4.4</h5><blockquote><p>关于 fork 函数的两个返回值，下面说法正确的是：</p><p> A、fork 在父进程中被调用两次，产生两个返回值 </p><p>B、fork 在两个进程中分别被调用一次，产生两个不同的返回值 </p><p>C、fork 只在父进程中被调用了一次，在两个进程中各产生一个返回值 D、fork 只在子进程中被调用了一次，在两个进程中各产生一个返回值</p></blockquote><p>C</p><h5 id="Thinking-4-5"><a href="#Thinking-4-5" class="headerlink" title="Thinking 4.5"></a>Thinking 4.5</h5><blockquote><p>我们并不应该对所有的用户空间页都使用 duppage 进行映射。那么究竟哪 些用户空间页应该映射，哪些不应该呢？请结合 kern/env.c 中 env_init 函数进行的页 面映射、include/mmu.h 里的内存布局图以及本章的后续描述进行思考。</p></blockquote><p>UCOW-UTEXT中的内存是被COW保护的所以不应该进行映射，0-UTEMP的内存为invalid memory ，不应该进行映射，UTEMP-UCOW的内存是暂时保护的内存，不需要映射。</p><h5 id="Thinking-4-6"><a href="#Thinking-4-6" class="headerlink" title="Thinking 4.6"></a>Thinking 4.6</h5><blockquote><p>在遍历地址空间存取页表项时你需要使用到 vpd和 vpt这两个指针，请参 考user/include/lib.h 中的相关定义，思考并回答这几个问题： </p><p>• vpt 和 vpd 的作用是什么？怎样使用它们？ </p><p>• 从实现的角度谈一下为什么进程能够通过这种方式来存取自身的页表？ </p><p>• 它们是如何体现自映射设计的？ </p><p>• 进程能够通过这种方式来修改自己的页表项吗？</p></blockquote><p>作用: 在用户态下通过访问进程自己的物理内存获取用户页的页目录项页表项的 perm，用于 duppage 根据不同的 perm 类型在父子进程间执行不同的物理页映射；</p><p>使用：vpd是页目录首地址，以vpd为基地址，加上页目录项偏移数即可指向va对应页目录项; vpt是页表首地址，以vpt为基地址，加上页表项偏移数即可指向va对应的页表项。</p><p>因为页目录映射和页表映射使得进程能够存取自身页表。</p><p>vpd的地址在UVPT和UVPT + PDMAP之间，说明将页目录映射到了某一页表位置(即实现了自映射);</p><p>不能。该部分区域对用户只读不写。</p><h5 id="Thinking-4-7"><a href="#Thinking-4-7" class="headerlink" title="Thinking 4.7"></a>Thinking 4.7</h5><blockquote><p>在 do_tlb_mod 函数中，你可能注意到了一个向异常处理栈复制 Trapframe 运行现场的过程，请思考并回答这几个问题： </p><p>• 这里实现了一个支持类似于“异常重入”的机制，而在什么时候会出现这种“异常重 入”？ </p><p>• 内核为什么需要将异常的现场 Trapframe复制到用户空间？</p></blockquote><p>当出现COW异常时，需要使用用户态的系统调用，此时会出现这种异常重入；由于用户态把异常处理完毕后仍然在用户态恢复现场，所以此时要把内核保存的现场保存在用户空间的用户异常栈。</p><h5 id="Thinking-4-8"><a href="#Thinking-4-8" class="headerlink" title="Thinking 4.8"></a>Thinking 4.8</h5><blockquote><p> 在用户态处理页写入异常，相比于在内核态处理有什么优势？</p></blockquote><p>释放内核，不需要内核执行大量工作；影响小，用户状态下不能得到一些在内核状态才有的权限，避免改变不必要的内存空间，内核态处理失误产生的影响较大，可能会使得操作系统崩溃。</p><h5 id="Thinking-4-9"><a href="#Thinking-4-9" class="headerlink" title="Thinking 4.9"></a>Thinking 4.9</h5><blockquote><p>请思考并回答以下几个问题： </p><p>• 为什么需要将 syscall_set_tlb_mod_entry的调用放置在 syscall_exofork之前？ </p><p>• 如果放置在写时复制保护机制完成之后会有怎样的效果？</p></blockquote><p>syscall_exofork()执行后，子进程和父进程各自执行，子进程需要改变entry.S中的env指针，会触发COW写入异常，中断处理机制需要syscall_set_tlb_mod_entry()执行，所以将 syscall_set_tlb_mod_entry 的调用放置在 syscall_exofork 之前；父进程在调用写时复制保护机制可能会引发缺页异常，而异常处理未设置好，则不能正常处理。</p><h4 id="二、实验难点"><a href="#二、实验难点" class="headerlink" title="二、实验难点"></a>二、实验难点</h4><h5 id="do-syscall函数"><a href="#do-syscall函数" class="headerlink" title="do-syscall函数"></a>do-syscall函数</h5><p>do_syscall函数借助保存的Trapframe结构体获取用户态中传递过来的值，从而恢复用户态现场。</p><p>首先需要从syscall_table中取得调用的函数:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">func &#x3D; syscall_table[sysno];</span><br></pre></td></tr></table></figure><p>再将tf指针中的保存的值存入参数中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">u_int arg1 &#x3D; tf-&gt;regs[5];</span><br><span class="line">u_int arg2 &#x3D; tf-&gt;regs[6];</span><br><span class="line">u_int arg3 &#x3D; tf-&gt;regs[7];</span><br><span class="line">arg4 &#x3D; *(u_int *)(tf-&gt;regs[29] + 16);  &#x2F;&#x2F; $sp + 16 bytes</span><br><span class="line">arg5 &#x3D; *(u_int *)(tf-&gt;regs[29] + 20);</span><br></pre></td></tr></table></figure><p>最后调用func函数，同时将其返回值存入寄存器中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf-&gt;regs[2] &#x3D; func(arg1, arg2, arg3, arg4, arg5);</span><br></pre></td></tr></table></figure><h5 id="envid2env函数"><a href="#envid2env函数" class="headerlink" title="envid2env函数"></a>envid2env函数</h5><p>这个函数主要功能是将envid转换为env，我们首先需要判断是否为curenv：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if (envid &#x3D;&#x3D; 0) &#123;</span><br><span class="line">*penv &#x3D; curenv;</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果不是则从envs[]取出对应的env:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e &#x3D; &amp;envs[ENVX(envid)];</span><br></pre></td></tr></table></figure><p>注意ENVX的功能是将envid转换为对应其在envs[]中的位置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define ENVX(envid) ((envid) &amp; (NENV - 1))</span><br></pre></td></tr></table></figure><p>还需要判断checkperm:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (checkperm &amp;&amp; e-&gt;env_id !&#x3D; curenv-&gt;env_id &amp;&amp; e-&gt;env_parent_id !&#x3D; curenv-&gt;env_id) &#123;</span><br><span class="line">return -E_BAD_ENV;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="sys-exofork函数"><a href="#sys-exofork函数" class="headerlink" title="sys_exofork函数"></a>sys_exofork函数</h5><p>我们需要复制一份当前进程的运行现场（进程上下文）Trapframe到子进程的进程控制 块中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e-&gt;env_tf &#x3D; *((struct Trapframe *)KSTACKTOP - 1);</span><br></pre></td></tr></table></figure><h5 id="duppage函数"><a href="#duppage函数" class="headerlink" title="duppage函数"></a>duppage函数</h5><p>我们要对不同权限位的页使用不同方式进行处理。</p><p>只读页面：对于不具有PTE_D权限位的页面，按照相同权限（只读）映射给子进程即可。</p><p>写时复制页面：即具有PTE_COW 权限位的页面。这类页面是之前的 fork 时 duppage 的结 果，且在本次fork前必然未被写入过。</p><p>共享页面：即具有PTE_LIBRARY 权限位的页面。这类页面需要保持共享可写的状态，即在 父子进程中映射到相同的物理页，使对其进行修改的结果相互可见。在文件系统部分的实 验中，我们会使用到这样的页面。</p><p>可写页面：即具有PTE_D权限位，且不符合以上特殊情况的页面。这类页面需要在父进程和 子进程的页表项中都使用PTE_COW权限位进行保护。</p><p>我们只需判断perm是否具有PTE_D同时不具有PTE_LIBRARY，如果满足条件，则还需调用syscall_mem_map函数将当前进程映射到其自身页面上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">r &#x3D; 0;</span><br><span class="line">if ((perm &amp; PTE_D) &amp;&amp; ((perm &amp; PTE_LIBRARY) &#x3D;&#x3D; 0)) &#123;</span><br><span class="line">perm &#x3D; perm &amp; ~PTE_D | PTE_COW;</span><br><span class="line">r &#x3D; 1;</span><br><span class="line">try(syscall_mem_map(0, addr, envid, addr, perm));</span><br><span class="line">&#125; else &#123;</span><br><span class="line">try(syscall_mem_map(0, addr, envid, addr, perm));</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">if (r) &#123;</span><br><span class="line">try(syscall_mem_map(0, addr, 0, addr, perm));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="三、体会与感想"><a href="#三、体会与感想" class="headerlink" title="三、体会与感想"></a>三、体会与感想</h4><p>本次实验对主要需要掌握：系统调用，IPC通信机制，fork进程创建，页面写入异常处理，难度相较而言比较大，需要更仔细。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OS-lab3</title>
      <link href="/2024/04/08/BUAA-OS-lab3/"/>
      <url>/2024/04/08/BUAA-OS-lab3/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OS-lab3"><a href="#BUAA-OS-lab3" class="headerlink" title="BUAA-OS-lab3"></a>BUAA-OS-lab3</h3><h4 id="一、实验思考题"><a href="#一、实验思考题" class="headerlink" title="一、实验思考题"></a>一、实验思考题</h4><h5 id="Thinking-3-1"><a href="#Thinking-3-1" class="headerlink" title="Thinking 3.1"></a>Thinking 3.1</h5><blockquote><p>请结合MOS中的页目录自映射应用解释代码中e-&gt;env_pgdir[PDX(UVPT)] &#x3D; PADDR(e-&gt;env_pgdir) | PTE_V 的含义。</p></blockquote><p>进程e中页目录的第PDX(UVPT)个页目录项等于页目录所在页表的基地址加上页表项有效位。</p><h5 id="Thinking-3-2"><a href="#Thinking-3-2" class="headerlink" title="Thinking 3.2"></a>Thinking 3.2</h5><blockquote><p>elf_load_seg以函数指针的形式，接受外部自定义的回调函数map_page。 请你找到与之相关的data这一参数在此处的来源，并思考它的作用。没有这个参数可不可 以？为什么？</p></blockquote><p>data的来源是Env结构体指针，它的作用是传给elf_load_seg函数，并作为map_page函数的参数，获得结构体的页目录。</p><h5 id="Thinking-3-3"><a href="#Thinking-3-3" class="headerlink" title="Thinking 3.3"></a>Thinking 3.3</h5><blockquote><p>结合elf_load_seg的参数和实现，考虑该函数需要处理哪些页面加载的情况。</p></blockquote><p>该函数需要考虑bin_size起始点、bin_size大小和sgsize大小以及地址对齐情况。</p><h5 id="Thinking-3-4"><a href="#Thinking-3-4" class="headerlink" title="Thinking 3.4"></a>Thinking 3.4</h5><blockquote><p>思考上面这一段话，并根据自己在Lab2中的理解，回答：</p><p>你认为这里的env_tf.cp0_epc存储的是物理地址还是虚拟地址?</p></blockquote><p>我认为env_tf.cp0_epc存储的是物理地址。</p><h5 id="Thinking-3-5"><a href="#Thinking-3-5" class="headerlink" title="Thinking 3.5"></a>Thinking 3.5</h5><blockquote><p>试找出0、1、2、3号异常处理函数的具体实现位置。8号异常（系统调用） 涉及的do_syscall()函数将在Lab4中实现。</p></blockquote><p>0号异常handle_int在genex.S实现，1号异常的处理函数为handle_mod在tlbex.c中实现，2号异常的处理函数handle_tlb和3号异常的处理函数为handle_tlb在tlb_asm.S中实现。</p><h5 id="Thinking-3-6"><a href="#Thinking-3-6" class="headerlink" title="Thinking 3.6"></a>Thinking 3.6</h5><blockquote><p>阅读 entry.S、genex.S 和 env_asm.S 这几个文件，并尝试说出时钟中断 在哪些时候开启，在哪些时候关闭。</p></blockquote><p>时钟中断在调用 env_pop_tf 函数时开启，在恢复现场、异常返回后关闭。</p><h4 id="二、实验难点"><a href="#二、实验难点" class="headerlink" title="二、实验难点"></a>二、实验难点</h4><h5 id="env-init-函数"><a href="#env-init-函数" class="headerlink" title="env_init 函数"></a>env_init 函数</h5><p>需要按倒序将所有控制块插入到空闲链表的头部，使得编号更小的进程控制块被优先分配。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for (i &#x3D; NENV - 1; i &gt;&#x3D; 0; i--) &#123;</span><br><span class="line">envs[i].env_status &#x3D; ENV_FREE;</span><br><span class="line">LIST_INSERT_HEAD(&amp;env_free_list, &amp;envs[i], env_link);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="env-setup-vm-函数"><a href="#env-setup-vm-函数" class="headerlink" title="env_setup_vm 函数"></a>env_setup_vm 函数</h5><p>难点在于为进程页目录分配地址时需要进行的地址转换，此过程需要调用<strong>page2kva</strong>函数将页面转变为虚拟地址，再将其赋值给e-&gt;env_pgdir。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">e-&gt;env_pgdir &#x3D; (Pde *)page2kva(p);</span><br></pre></td></tr></table></figure><h5 id="env-alloc函数"><a href="#env-alloc函数" class="headerlink" title="env_alloc函数"></a>env_alloc函数</h5><p>先从env_free_list中获得新的Env，并判断是否为空。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if((e &#x3D; LIST_FIRST(&amp;env_free_list)) &#x3D;&#x3D; NULL) &#123;</span><br><span class="line">return -E_NO_FREE_ENV;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再使用env_setup_vm函数初始化Env。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">env_setup_vm(e);</span><br></pre></td></tr></table></figure><p>初始化Env中的一系列需要初始化的参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">asid_alloc(&amp;(e-&gt;env_asid));</span><br><span class="line">e-&gt;env_id &#x3D; mkenvid(e);</span><br><span class="line">e-&gt;env_parent_id &#x3D; parent_id;</span><br></pre></td></tr></table></figure><p>再将Env从env_free_list中移除。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LIST_REMOVE(e, env_link);</span><br></pre></td></tr></table></figure><h5 id="load-icode-mapper函数"><a href="#load-icode-mapper函数" class="headerlink" title="load_icode_mapper函数"></a>load_icode_mapper函数</h5><p>难点在于如何使用<strong>memcpy</strong>函数将从src开始的len大小的字节复制到这一页的偏移量地址上。注意需要使用<strong>page2kva</strong>将页面地址转化为虚拟地址。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (offset + len &lt;&#x3D; PAGE_SIZE) &#123;</span><br><span class="line">memcpy(page2kva(p) + offset, src, len);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="schedule函数"><a href="#schedule函数" class="headerlink" title="schedule函数"></a>schedule函数</h5><p>这是本次实验最难的一部分，需要完成对进程的调度函数。根据注释的提示来完成，我们总是将“计数”减少1。如果设置了’yield’，或者’count’已减少为0，或者’e’(之前的’ currenv ‘)为’NULL’，或者’e’不可运行，那么我们从’env_sched_list’(所有可运行的env列表)中拾取一个新的env，将’count’设置为其优先级，并将其与’env_run’调度。<strong>如果列表是空的</strong>。(注意，如果’e’仍然是一个可运行的环境，我们应该将它移到’env_sched_list’的尾部，然后再从它的头部获取另一个环境，否则我们将重复调度头部环境。)否则，我们只需再次安排“e”。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">if (e &#x3D;&#x3D; NULL || count &#x3D;&#x3D; 0 || e-&gt;env_status !&#x3D; ENV_RUNNABLE || yield !&#x3D; 0) &#123;</span><br><span class="line">if (e !&#x3D; NULL &amp;&amp; e-&gt;env_status &#x3D;&#x3D; ENV_RUNNABLE) &#123;</span><br><span class="line"> if (yield &amp;&amp; TAILQ_FIRST(&amp;env_sched_list) !&#x3D; NULL) &#123;</span><br><span class="line"></span><br><span class="line">&#125; else &#123;</span><br><span class="line">TAILQ_INSERT_TAIL(&amp;env_sched_list, e, env_sched_link);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if ((e &#x3D; TAILQ_FIRST(&amp;env_sched_list)) &#x3D;&#x3D; NULL) &#123;</span><br><span class="line">panic(&quot;schedule: no runnable envs&quot;);</span><br><span class="line">&#125; </span><br><span class="line">TAILQ_REMOVE(&amp;env_sched_list, e, env_sched_link);</span><br><span class="line">count &#x3D; e-&gt;env_pri;</span><br><span class="line">count--;</span><br><span class="line">env_run(e);</span><br><span class="line"></span><br><span class="line">&#125; else &#123;</span><br><span class="line">count--;</span><br><span class="line">env_run(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="三、体会与感想"><a href="#三、体会与感想" class="headerlink" title="三、体会与感想"></a>三、体会与感想</h4><p>个人认为lab3的总体难度是大于之前的lab的，难点在于进程的调度、地址转换以及一些变量含义的理解。从Lab3遇到Bug会比较瞻前顾后，不知道是本次Lab还是之前Lab的bug，排查Bug所在范围的过程比较头疼。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OS-lab2</title>
      <link href="/2024/03/25/BUAA-OS-lab2/"/>
      <url>/2024/03/25/BUAA-OS-lab2/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OS-Lab2"><a href="#BUAA-OS-Lab2" class="headerlink" title="BUAA_OS_Lab2"></a>BUAA_OS_Lab2</h3><h4 id="一、实验思考题"><a href="#一、实验思考题" class="headerlink" title="一、实验思考题"></a>一、实验思考题</h4><h5 id="Thinking-2-1"><a href="#Thinking-2-1" class="headerlink" title="Thinking 2.1"></a>Thinking 2.1</h5><blockquote><p> 请根据上述说明，回答问题：在编写的 C 程序中，指针变量中存储的地址被视为虚拟地址，还是物理地址？MIPS汇编程序中lw和sw指令使用的地址被视为虚拟 地址，还是物理地址？</p></blockquote><p>指针变量中存储的地址是虚拟地址，MIPS汇编程序中lw和sw指令使用的地址也是虚拟地址。</p><h5 id="Thinking-2-2"><a href="#Thinking-2-2" class="headerlink" title="Thinking 2.2"></a>Thinking 2.2</h5><blockquote><p>请思考下述两个问题： </p><ul><li>从可重用性的角度，阐述用宏来实现链表的好处。 </li><li>查看实验环境中的&#x2F;usr&#x2F;include&#x2F;sys&#x2F;queue.h，了解其中单向链表与循环链表的实现，比较它们与本实验中使用的双向链表，分析三者在插入与删除操作上的性能差异。</li></ul></blockquote><p>宏实现链表可以减少代码的复用，可重用性强，链表的插入和删除等操作使用宏可以保证这些操作都是一致的，从而减少了出错的可能性，可读性强，易于维护。</p><p>单向链表简单的插入与删除操作时间复杂度为O(1), 但是对任意的第n个元素的插入和删除操作需要遍历链表，时间复杂度为O(N); 双向链表对于任意第n个元素的插入与删除操作时间复杂度都为O(1); 循环链表中单向循环链表与单向链表一样，对任意的第n个元素的插入和删除操作时间复杂度为O(N)，双向循环链表对于任意第n个元素的插入与删除操作时间复杂度都为O(1)。</p><h5 id="Thinking-2-3"><a href="#Thinking-2-3" class="headerlink" title="Thinking 2.3"></a>Thinking 2.3</h5><blockquote><p>请阅读include&#x2F;queue.h以及include&#x2F;pmap.h,将Page_list的结构梳 理清楚，选择正确的展开结构。</p></blockquote><p>C</p><h5 id="Thinking-2-4"><a href="#Thinking-2-4" class="headerlink" title="Thinking 2.4"></a>Thinking 2.4</h5><blockquote><p>请思考下面两个问题：</p><ul><li>请阅读上面有关TLB的描述，从虚拟内存和多进程操作系统的实现角度，阐述ASID 的必要性。 </li><li>请阅读 MIPS 4Kc 文档《MIPS32® 4K™ Processor Core Family Software User’s Manual》的 Section 3.3.1 与 Section 3.4，结合 ASID 段的位数，说明 4Kc 中可容纳不同的地址空间的最大数量。</li></ul></blockquote><p>ASID用于区分不同的地址空间，同一虚拟地址在不同的地址空间中通常映射到不同的物理地址。ASID机制可以确保一个进程无法访问其他进程的内存区域，从而实现地址空间的隔离，起到内存保护的作用。同时，多进程操作系统通过ASID来管理和跟踪每个进程的虚拟地址空间。当进程切换时，操作系统可以根据ASID更新TLB的内容。</p><p>ASID段位数为8位，所以4Kc 中可容纳不同的地址空间的最大数量为256。</p><h5 id="Thinking-2-5"><a href="#Thinking-2-5" class="headerlink" title="Thinking 2.5"></a>Thinking 2.5</h5><blockquote><p>请回答下述三个问题： </p><ul><li>tlb_invalidate和tlb_out的调用关系？ </li><li>请用一句话概括tlb_invalidate的作用。 </li><li>逐行解释tlb_out中的汇编代码。</li></ul></blockquote><p>tlb_invalidate调用tlb_out; tlb_invalidate 函数实现删除特定虚拟地址在 TLB中的旧表项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;asm&#x2F;asm.h&gt;</span><br><span class="line"></span><br><span class="line">LEAF(tlb_out) </span><br><span class="line">.set noreorder</span><br><span class="line">mfc0    t0, CP0_ENTRYHI &#x2F;&#x2F;将当前的VPN和ASID存储到t0寄存器中，用于后续恢复CP0_ENTRYHI </span><br><span class="line">mtc0    a0, CP0_ENTRYHI &#x2F;&#x2F;将调用函数传入的旧表项的Key(由VPN和ASID组成)写进CP0_ENTRYHI </span><br><span class="line">nop</span><br><span class="line">&#x2F;* Step 1: Use &#39;tlbp&#39; to probe TLB entry *&#x2F;</span><br><span class="line">&#x2F;* Exercise 2.8: Your code here. (1&#x2F;2) *&#x2F;</span><br><span class="line">tlbp &#x2F;&#x2F;根据CP0_EntryHi中的Key查找TLB中对应的旧表项，将表项的索引存入CP0_Index。</span><br><span class="line">nop</span><br><span class="line">&#x2F;* Step 2: Fetch the probe result from CP0.Index *&#x2F;</span><br><span class="line">mfc0    t1, CP0_INDEX &#x2F;&#x2F;将CP0_Index存储t1寄存器。</span><br><span class="line">.set reorder</span><br><span class="line">bltz    t1, NO_SUCH_ENTRY &#x2F;&#x2F;如果t1寄存器中的值小于0（即TLB中不存在</span><br><span class="line">Key对应的表项），跳转到NO_SUCH_ENTRY标签处。</span><br><span class="line">.set noreorder</span><br><span class="line">&#x2F;&#x2F;如果t1寄存器中的值大于等于0（即TLB中存在Key对应的表项），我们向EntryHi和EntryLo0、EntryLo1中写入0</span><br><span class="line">mtc0    zero, CP0_ENTRYHI</span><br><span class="line">mtc0    zero, CP0_ENTRYLO0</span><br><span class="line">mtc0    zero, CP0_ENTRYLO1</span><br><span class="line">nop</span><br><span class="line">&#x2F;* Step 3: Use &#39;tlbwi&#39; to write CP0.EntryHi&#x2F;Lo into TLB at CP0.Index  *&#x2F;</span><br><span class="line">&#x2F;* Exercise 2.8: Your code here. (2&#x2F;2) *&#x2F;</span><br><span class="line">tlbwi   &#x2F;&#x2F;将EntryHi和EntryLo0、EntryLo1中的值写入索引指定的表项。此时旧表项的Key和Data被清零，实现将其无效化</span><br><span class="line">.set reorder</span><br><span class="line"></span><br><span class="line">NO_SUCH_ENTRY:</span><br><span class="line">mtc0    t0, CP0_ENTRYHI &#x2F;&#x2F;将原始的ENTRYHI寄存器的值（保存在t0中）恢复回ENTRYHI寄存器。</span><br><span class="line">j       ra &#x2F;&#x2F;函数结束并返回</span><br><span class="line">END(tlb_out)</span><br></pre></td></tr></table></figure><h5 id="Thinking-A-1"><a href="#Thinking-A-1" class="headerlink" title="Thinking A.1"></a>Thinking A.1</h5><blockquote><p>在现代的 64 位系统中，提供了 64 位的字长，但实际上不是 64 位页式存 储系统。假设在64位系统中采用三级页表机制，页面大小4KB。由于64位系统中字长为 8B，且页目录也占用一页，因此页目录中有512 个页目录项，因此每级页表都需要9位。 因此在64位系统下，总共需要3×9+12&#x3D;39位就可以实现三级页表机制，并不需要64 位。现考虑上述39位的三级页式存储系统，虚拟地址空间为512GB，若三级页表的基地 址为PTbase，请计算： </p><p>•三级页表页目录的基地址。 </p><p>•映射到页目录自身的页目录项（自映射）。</p></blockquote><p>三级页表页目录的基地址是(PTbase &gt;&gt; 30) &lt;&lt; 30; 映射到页目录自身的页目录项（自映射）为PTbase + ((PTbase &gt;&gt; 12) &lt;&lt; 3)  + ((((PTbase &gt;&gt; 12) &lt;&lt; 3) &gt;&gt; 12) &lt;&lt; 3) + ((((((PTbase &gt;&gt; 12) &lt;&lt; 3) &gt;&gt; 12) &lt;&lt; 3) &gt;&gt; 12) &lt;&lt; 3)</p><h5 id="Thinking-2-6"><a href="#Thinking-2-6" class="headerlink" title="Thinking 2.6"></a>Thinking 2.6</h5><blockquote><p>从下述三个问题中任选其一回答：</p><p>• 简单了解并叙述X86体系结构中的内存管理机制，比较X86和MIPS在内存管理上 的区别。<br>• 简单了解并叙述RISC-V 中的内存管理机制，比较RISC-V 与 MIPS 在内存管理上 的区别。 </p><p>• 简单了解并叙述LoongArch 中的内存管理机制，比较 LoongArch 与 MIPS 在内存 管理上的区别。</p></blockquote><p>X86 体系结构中的内存管理机制: </p><ul><li>通过分段将逻辑地址转换为线性地址，通过分页将线性地址转换为物理地址。</li><li>X86采用分段机制来管理内存。内存被划分为多个段，每个段都有起始地址和长度描述。CPU通过逻辑地址访问内存，这个逻辑地址包含段选择符和偏移量。</li><li>当CPU尝试访问某个内存位置时，它会使用段选择符在段描述符表中查找对应的段描述符，然后根据段描述符中的基地址和偏移量相加就是线性地址。</li><li>X86使用分页机制来进一步管理内存。内存被划分为固定大小的页面，每个页面都有一个唯一的物理地址。</li><li>操作系统创建全局描述符表和提供逻辑地址，之后的分段操作x86的CPU会自动完成，并找到对应的线性地址。</li><li>从线性地址到物理地址的转换是CPU自动完成的，转化时使用的Page Directory和Page Table等需要操作系统提供。</li></ul><p>X86和MIPS在内存管理上的区别：</p><ul><li>在TLB处理方面，当TLB不命中时（即TLB中没有缓存所需的虚拟地址到物理地址的映射关系），MIPS会触发一个异常（如TLB Refill异常），然后由内核的特定处理程序来处理这个异常并更新TLB。而X86则是由硬件的MMU（内存管理单元）直接处理不命中情况，它会使用页表来找到正确的物理地址，并更新TLB以便下次快速访问。</li><li>MIPS属于RISC（精简指令集计算机）架构，其指令集固定长度且数量有限，通常通过Load&#x2F;Store指令来访问内存。而X86则属于CISC（复杂指令集计算机）架构，其指令集更加丰富和复杂，包括多种直接操作内存的指令。</li><li>分页方式不同：一种MIPS系统内部只有一种分页方式，x86的CPU支持三种分页模式。</li><li>逻辑地址不同：MIPS地址空间32位，x86支持64位逻辑地址，同时提供转换为32位定址选项。</li></ul><h4 id="二、实验难点"><a href="#二、实验难点" class="headerlink" title="二、实验难点"></a>二、实验难点</h4><h5 id="mips-detect-memory-函数补全"><a href="#mips-detect-memory-函数补全" class="headerlink" title="mips_detect_memory 函数补全"></a>mips_detect_memory 函数补全</h5><p>总页数npage等于memsize除以单个页面的大小。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npage &#x3D; memsize &#x2F; PAGE_SIZE;</span><br></pre></td></tr></table></figure><h5 id="LIST-INSERT-AFTER函数"><a href="#LIST-INSERT-AFTER函数" class="headerlink" title="LIST_INSERT_AFTER函数"></a>LIST_INSERT_AFTER函数</h5><p> LIST_INSERT_AFTER的作用是将新加elm节点插入到链表现有listelm结点之后，我们需要利用已经定义的宏<strong>LIST_NEXT(elm, field)<strong>，按照</strong>LIST_INSERT_BEFORE</strong>的写法来完成函数。<strong>注意</strong>：宏定义函数每行需要用“\”进行链接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#define LIST_NEXT(elm, field) ((elm)-&gt;field.le_next)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#define LIST_INSERT_BEFORE(listelm, elm, field)                                                    \</span><br><span class="line">do &#123;                                                                                       \</span><br><span class="line">(elm)-&gt;field.le_prev &#x3D; (listelm)-&gt;field.le_prev;                                   \</span><br><span class="line">LIST_NEXT((elm), field) &#x3D; (listelm);                                               \</span><br><span class="line">*(listelm)-&gt;field.le_prev &#x3D; (elm);                                                 \</span><br><span class="line">(listelm)-&gt;field.le_prev &#x3D; &amp;LIST_NEXT((elm), field);                               \</span><br><span class="line">&#125; while (0)</span><br></pre></td></tr></table></figure><p>根据注释的提示，我们第一步需要将<strong>listelm.next</strong>分配给<strong>elm.next</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LIST_NEXT((elm), field) &#x3D; LIST_NEXT((listelm), field); &#x2F;&#x2F; assign &#39;elm.next&#39; from &#39;listelm.next&#39;.</span><br></pre></td></tr></table></figure><p>第二步：如果<strong>listelm.next</strong>不为空，则将<strong>elm</strong>分配为<strong>listelm.next</strong>的前一个节点<strong>listelm.next.pre</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if(LIST_NEXT((listelm), field)) &#123;   \</span><br><span class="line">*((LIST_NEXT((listelm), field))-&gt;field.le_prev) &#x3D; (elm);                   \</span><br><span class="line">(LIST_NEXT((listelm), field))-&gt;field.le_prev &#x3D; &amp;LIST_NEXT((elm), field);   \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第三步：将<strong>elm</strong>分配为<strong>listelm.next</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LIST_NEXT((listelm), field) &#x3D; (elm);</span><br></pre></td></tr></table></figure><p>第四步：将<strong>elm</strong>的前一个结点<strong>elm.pre</strong>置为<strong>listelm.next</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(elm)-&gt;field.le_prev &#x3D; &amp;LIST_NEXT((listelm), field);</span><br></pre></td></tr></table></figure><h5 id="page-init函数"><a href="#page-init函数" class="headerlink" title="page_init函数"></a>page_init函数</h5><p>需要利用<strong>LIST_INIT</strong>函数先初始化链表。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#define LIST_INIT(head)                                                                            \</span><br><span class="line">do &#123;                                                                                       \</span><br><span class="line">LIST_FIRST((head)) &#x3D; NULL;                                                         \</span><br><span class="line">&#125; while (0)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LIST_INIT(&amp;page_free_list);</span><br></pre></td></tr></table></figure><p>再利用<strong>ROUND</strong>函数将<strong>freemem</strong>与<strong>PAGE_SIZE</strong>大小对齐。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">freemem &#x3D; ROUND(freemem, PAGE_SIZE);</span><br></pre></td></tr></table></figure><p>接着将<strong>freemem</strong>以下的内存的标记为<strong>used</strong>表明已使用过，即<strong>pp_ref</strong>置为1。需要用的页表头指针<strong>pages</strong>，计算出使用过的空间的页面数量，用循环遍历的方法赋值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">struct Page *pp &#x3D; pages;</span><br><span class="line">u_long used &#x3D; freemem &amp; (0x80000000 - 1);</span><br><span class="line">int p1 &#x3D; used &#x2F; PAGE_SIZE;</span><br><span class="line">int i &#x3D; 0;</span><br><span class="line">for (i &#x3D; 0; i &lt; p1; i++) &#123;</span><br><span class="line">pp-&gt;pp_ref &#x3D; 1;</span><br><span class="line">pp++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后将其他内存标记为<strong>free</strong>，表示没使用过并使用LIST_INSERT_HEAD 将 其插入空闲链表。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">while (i &lt; npage) &#123;</span><br><span class="line">pp-&gt;pp_ref &#x3D; 0;</span><br><span class="line">LIST_INSERT_HEAD(&amp;page_free_list, pp, pp_link);</span><br><span class="line">pp++;</span><br><span class="line">i++; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="page-alloc-函数"><a href="#page-alloc-函数" class="headerlink" title="page_alloc 函数"></a>page_alloc 函数</h5><p>从空闲空间中取一个页面，如果不成功，则返回错误。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (LIST_EMPTY(&amp;page_free_list)) &#123;</span><br><span class="line">return -E_NO_MEM;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<strong>memset</strong>函数初始化这个页面，如果空闲链表有可用的页，取出链表头部的一页；初始化后，将该页对应的页 控制块的地址放到调用者指定的地方。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct Page *pp;</span><br><span class="line">pp &#x3D; LIST_FIRST(&amp;page_free_list);</span><br><span class="line">LIST_REMOVE(pp, pp_link);</span><br><span class="line">memset((void *)page2kva(pp), 0, PAGE_SIZE);</span><br><span class="line">*new &#x3D; pp;</span><br></pre></td></tr></table></figure><h5 id="page-free-函数"><a href="#page-free-函数" class="headerlink" title="page_free 函数"></a>page_free 函数</h5><p>使用链表宏LIST_INSERT_HEAD，将页结构体插入空闲页结构体链表。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void page_free(struct Page *pp) &#123;</span><br><span class="line">assert(pp-&gt;pp_ref &#x3D;&#x3D; 0);</span><br><span class="line">&#x2F;* Just insert it into &#39;page_free_list&#39;. *&#x2F;</span><br><span class="line">&#x2F;* Exercise 2.5: Your code here. *&#x2F;</span><br><span class="line">LIST_INSERT_HEAD(&amp;page_free_list, pp, pp_link);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="pgdir-walk函数"><a href="#pgdir-walk函数" class="headerlink" title="pgdir_walk函数"></a>pgdir_walk函数</h5><p>该函数的作用是：给定一个虚拟地址，在给定的页目录中查找这个虚拟地址对应的页表项，将其地址写入<em>ppte。如果这一虚拟地址对应的二级页表存在，则设置</em>ppte为这一页表项的地址；如果这一虚拟地址对应的二级页表不存在（即这一虚拟地址对应的页目录项无效）， 则当create不为0时先创建二级页表再查找页表项，为0时则将*ppte设置为空指针。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">pgdir_entryp &#x3D; &amp;pgdir[PDX(va)];</span><br><span class="line">if (!(*pgdir_entryp &amp; PTE_V)) &#123;</span><br><span class="line">if (create) &#123;</span><br><span class="line">if (page_alloc(&amp;pp) &#x3D;&#x3D; 0) &#123;</span><br><span class="line">*pgdir_entryp &#x3D; page2pa(pp) | PTE_C_CACHEABLE | PTE_V;</span><br><span class="line">pp-&gt;pp_ref++;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">return -E_NO_MEM;</span><br><span class="line">&#125;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">*ppte &#x3D; NULL;</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">Pte *pgt &#x3D; (Pte*)KADDR(PTE_ADDR(*pgdir_entryp));</span><br><span class="line">*ppte &#x3D; &amp;pgt[PTX(va)];</span><br><span class="line">return 0;</span><br></pre></td></tr></table></figure><h5 id="page-insert函数"><a href="#page-insert函数" class="headerlink" title="page_insert函数"></a>page_insert函数</h5><p>但先要将TLB中缓存的页表项删掉，然后更新内存中的页表项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tlb_invalidate(asid, va);</span><br></pre></td></tr></table></figure><p>获得页表目录。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(pgdir_walk(pgdir, va, 1, &amp;pte) !&#x3D; 0) &#123;</span><br><span class="line">return -E_NO_MEM;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>插入新的页。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*pte &#x3D; page2pa(pp) | PTE_V | perm | PTE_C_CACHEABLE;</span><br><span class="line">pp-&gt;pp_ref++;</span><br></pre></td></tr></table></figure><h5 id="kern-tlb-asm-S中的tlb-out函数"><a href="#kern-tlb-asm-S中的tlb-out函数" class="headerlink" title="kern&#x2F;tlb_asm.S中的tlb_out函数"></a>kern&#x2F;tlb_asm.S中的tlb_out函数</h5><p>需要在两个位置插入两条指令，其中一个位置为tlbp，另一个位置为tlbwi。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">LEAF(tlb_out)</span><br><span class="line">.set noreorder</span><br><span class="line">mfc0    t0, CP0_ENTRYHI</span><br><span class="line">mtc0    a0, CP0_ENTRYHI</span><br><span class="line">nop</span><br><span class="line">&#x2F;* Step 1: Use &#39;tlbp&#39; to probe TLB entry *&#x2F;</span><br><span class="line">&#x2F;* Exercise 2.8: Your code here. (1&#x2F;2) *&#x2F;</span><br><span class="line">tlbp</span><br><span class="line">nop</span><br><span class="line">&#x2F;* Step 2: Fetch the probe result from CP0.Index *&#x2F;</span><br><span class="line">mfc0    t1, CP0_INDEX</span><br><span class="line">.set reorder</span><br><span class="line">bltz    t1, NO_SUCH_ENTRY</span><br><span class="line">.set noreorder</span><br><span class="line">mtc0    zero, CP0_ENTRYHI</span><br><span class="line">mtc0    zero, CP0_ENTRYLO0</span><br><span class="line">mtc0    zero, CP0_ENTRYLO1</span><br><span class="line">nop</span><br><span class="line">&#x2F;* Step 3: Use &#39;tlbwi&#39; to write CP0.EntryHi&#x2F;Lo into TLB at CP0.Index  *&#x2F;</span><br><span class="line">&#x2F;* Exercise 2.8: Your code here. (2&#x2F;2) *&#x2F;</span><br><span class="line">tlbwi   </span><br><span class="line">.set reorder</span><br></pre></td></tr></table></figure><h5 id="kern-tlbex-c中的-do-tlb-refill函数"><a href="#kern-tlbex-c中的-do-tlb-refill函数" class="headerlink" title="kern&#x2F;tlbex.c中的_do_tlb_refill函数"></a>kern&#x2F;tlbex.c中的_do_tlb_refill函数</h5><p>根据Hints来写就行。</p><blockquote><p>&#x2F;* Hints:</p><p>   *  Invoke ‘page_lookup’ repeatedly in a loop to find the page table entry ‘*ppte’</p><p>   * associated with the virtual address ‘va’ in the current address space ‘cur_pgdir’.</p><ul><li></li></ul><p>   *  <strong>While</strong> ‘page_lookup’ returns ‘NULL’, indicating that the ‘*ppte’ could not be found,</p><p>   *  allocate a new page using ‘passive_alloc’ until ‘page_lookup’ succeeds.</p><p>   *&#x2F;</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">while(1) &#123;</span><br><span class="line">if (page_lookup(cur_pgdir, va, &amp;ppte) &#x3D;&#x3D; NULL) &#123;</span><br><span class="line">passive_alloc(va, cur_pgdir, asid);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">break;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="kern-tlb-asm-S中的do-tlb-refill函数"><a href="#kern-tlb-asm-S中的do-tlb-refill函数" class="headerlink" title="kern&#x2F;tlb_asm.S中的do_tlb_refill函数"></a>kern&#x2F;tlb_asm.S中的do_tlb_refill函数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;* Hint: use &#39;tlbwr&#39; to write CP0.EntryHi&#x2F;Lo into a random tlb entry. *&#x2F;</span><br><span class="line">&#x2F;* Exercise 2.10: Your code here. *&#x2F;</span><br><span class="line">tlbwr</span><br></pre></td></tr></table></figure><h4 id="三、实验体会"><a href="#三、实验体会" class="headerlink" title="三、实验体会"></a>三、实验体会</h4><p>本次实验总体而言难度很大，主要是因为教程晦涩难懂而且要补全的代码大多需要使用许多前面定义的宏或者函数，这导致在写的时候需要耗费大量时间去了解这个宏或函数的用法，同时也需要注意一些细节，容易在细节上出错。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DeepLearning</title>
      <link href="/2024/03/17/DeepLearning/"/>
      <url>/2024/03/17/DeepLearning/</url>
      
        <content type="html"><![CDATA[<h2 id="DeepLearning"><a href="#DeepLearning" class="headerlink" title="DeepLearning"></a>DeepLearning</h2><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><h4 id="机器学习中的关键组件"><a href="#机器学习中的关键组件" class="headerlink" title="机器学习中的关键组件"></a>机器学习中的关键组件</h4><ul><li>可以用来学习的数据（data）；</li><li>转换数据的模型（model）；</li><li>一个目标函数（objective function），用来量化模型的有效性；</li><li>调整模型参数以优化目标函数的算法（algorithm）。</li></ul><h5 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h5><p>每个数据集由一个个样本（example, sample）组成，通常每个样本由一组称为<strong>特征</strong>（features，或<strong>协变量</strong>（covariates））的属性组成。</p><p>当每个样本的特征类别数量都是相同的时候，其<strong>特征向量</strong>是固定长度的，这个长度被称为数据的<strong>维数</strong>（dimensionality）。</p><p>与传统机器学习方法相比，深度学习的一个主要优势是<strong>可以处理不同长度的数据。</strong></p><h5 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h5><p>大多数机器学习会涉及到数据的转换。</p><p>深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为<em>深度学习</em>（deep learning）。</p><h5 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h5><p>在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为<strong>目标函数</strong>（objective function）。</p><p> 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为<strong>损失函数</strong>（loss function，或cost function）。</p><p>通常，损失函数是根据模型参数定义的，并取决于数据集。在一个数据集上，我们可以通过最小化总损失来学习模型参数的最佳值。该数据集由一些为训练而收集的样本组成，称为<strong>训练数据集</strong>（training dataset，或称为<em>训练集</em>（training set））。然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的性能，这里的“新数据集”通常称为<strong>测试数据集</strong>（test dataset，或称为<em>测试集</em>（test set））。</p><p>综上所述，可用数据集通常可以分成两部分：<strong>训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。</strong></p><p>当一个模型在训练集上表现良好，但不能推广到测试集时，这个模型被称为<strong>过拟合</strong>（overfitting）的。</p><h5 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h5><p>需要一种算法，它能够搜索出最佳参数，以最小化损失函数。</p><p>深度学习中，大多流行的优化算法通常基于一种基本方法–<strong>梯度下降</strong>（gradient descent）。</p><p>简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。</p><h4 id="各种机器学习问题"><a href="#各种机器学习问题" class="headerlink" title="各种机器学习问题"></a>各种机器学习问题</h4><h5 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h5><p><strong>监督学习</strong>（supervised learning）擅长在“给定输入特征”的情况下预测标签。 每个“特征-标签”对都称为一个<em>样本</em>（example）。 有时，即使标签是未知的，样本也可以指代输入特征。 我们的<strong>目标是生成一个模型，能够将任何输入特征映射到标签（即预测）。</strong></p><p><strong>监督学习的学习过程一般可以分为三大步骤：</strong></p><ul><li>从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。</li><li>选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；</li><li>将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测。</li></ul><p><strong>回归</strong></p><p><em>回归</em>（regression）是最简单的监督学习任务之一。</p><blockquote><p>假设有一组房屋销售数据表格，其中每行对应一个房子，每列对应一个相关的属性，例如房屋的面积、卧室的数量、浴室的数量以及到镇中心的步行距离，等等。 每一行的属性构成了一个房子样本的特征向量。 如果一个人住在纽约或旧金山，而且他不是亚马逊、谷歌、微软或Facebook的首席执行官，那么他家的特征向量（房屋面积，卧室数量，浴室数量，步行距离）可能类似于：[600,1,1,60]。 如果一个人住在匹兹堡，这个特征向量可能更接近[3000,4,3,10]…… 当人们在市场上寻找新房子时，可能需要估计一栋房子的公平市场价值。 为什么这个任务可以归类为回归问题呢？本质上是输出决定的。 销售价格（即标签）是一个数值。 </p></blockquote><p>当标签取任意数值时，我们称之为<strong>回归</strong>问题，此时的目标是生成一个模型，使它的预测非常接近实际标签值。</p><p>总而言之，判断回归问题的一个很好的经验法则是，任何有关“有多少”的问题很可能就是回归问题。</p><p><strong>分类</strong></p><blockquote><p>虽然回归模型可以很好地解决“有多少”的问题，但是很多问题并非如此。 例如，一家银行希望在其移动应用程序中添加支票扫描功能。 具体地说，这款应用程序能够自动理解从图像中看到的文本，并将手写字符映射到对应的已知字符之上。 </p></blockquote><p>这种“哪一个”的问题叫做<em>分类</em>（classification）问题。 <em>分类</em>问题希望模型能够预测样本属于哪个<em>类别</em>（category，正式称为<em>类</em>（class））。 </p><p>最简单的分类问题是只有两类，这被称之为<em>二项分类</em>（binomial classification）。</p><p>回归是训练一个回归函数来输出一个数值； 分类是训练一个分类器来输出预测的类别。</p><p>与解决回归问题不同，分类问题的常见损失函数被称为<strong>交叉熵</strong>（cross-entropy）</p><p><strong>标记问题</strong></p><p>学习预测不相互排斥的类别的问题称为<em>多标签分类</em>（multi-label classification）。</p><blockquote><p>举个例子，人们在技术博客上贴的标签，比如“机器学习”“技术”“小工具”“编程语言”“Linux”“云计算”“AWS”。 一篇典型的文章可能会用5～10个标签，因为这些概念是相互关联的。 关于“云计算”的帖子可能会提到“AWS”，而关于“机器学习”的帖子也可能涉及“编程语言”。</p></blockquote><p><strong>搜索</strong></p><p>有时，我们不仅仅希望输出一个类别或一个实值。 在信息检索领域，我们希望对一组项目进行排序。 以网络搜索为例，目标不是简单的“查询（query）-网页（page）”分类，而是在海量搜索结果中找到用户最需要的那部分。 搜索结果的排序也十分重要，学习算法需要输出有序的元素子集。 换句话说，如果要求我们输出字母表中的前5个字母，返回“A、B、C、D、E”和“C、A、B、E、D”是不同的。 即使结果集是相同的，集内的顺序有时却很重要。</p><p>该问题的一种可能的解决方案：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。</p><p><strong>推荐系统</strong></p><p>另一类与搜索和排名相关的问题是<em>推荐系统</em>（recommender system），它的目标是向特定用户进行“个性化”推荐。</p><p><strong>序列学习</strong></p><p>如果输入的样本之间没有任何关系，以上模型可能完美无缺。 但是如果输入是连续的，模型可能就需要拥有“记忆”功能。</p><h5 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h5><p>这类数据中不含有“目标”的机器学习问题通常被为<strong>无监督学习</strong>（unsupervised learning）</p><ul><li><em>聚类</em>（clustering）问题：没有标签的情况下，我们是否能给数据分类呢？比如，给定一组照片，我们能把它们分成风景照片、狗、婴儿、猫和山峰的照片吗？同样，给定一组用户的网页浏览记录，我们能否将具有相似行为的用户聚类呢？</li><li><em>主成分分析</em>（principal component analysis）问题：我们能否找到少量的参数来准确地捕捉数据的线性相关属性？比如，一个球的运动轨迹可以用球的速度、直径和质量来描述。再比如，裁缝们已经开发出了一小部分参数，这些参数相当准确地描述了人体的形状，以适应衣服的需要。另一个例子：在欧几里得空间中是否存在一种（任意结构的）对象的表示，使其符号属性能够很好地匹配?这可以用来描述实体及其关系，例如“罗马” − “意大利” + “法国” = “巴黎”。</li><li><em>因果关系</em>（causality）和<em>概率图模型</em>（probabilistic graphical models）问题：我们能否描述观察到的许多数据的根本原因？例如，如果我们有关于房价、污染、犯罪、地理位置、教育和工资的人口统计数据，我们能否简单地根据经验数据发现它们之间的关系？</li><li><em>生成对抗性网络</em>（generative adversarial networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域。</li></ul><h5 id="与环境互动"><a href="#与环境互动" class="headerlink" title="与环境互动"></a>与环境互动</h5><p>到目前为止，不管是监督学习还是无监督学习，我们都会预先获取大量数据，然后启动模型，不再与环境交互。 这里所有学习都是在算法与环境断开后进行的，被称为<em>离线学习</em>（offline learning）。</p><h5 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h5><p>如果你对使用机器学习开发与环境交互并采取行动感兴趣，那么最终可能会专注于<em>强化学习</em>（reinforcement learning）。 这可能包括应用到机器人、对话系统，甚至开发视频游戏的人工智能（AI）。 </p><p><em>深度强化学习</em>（deep reinforcement learning）将深度学习应用于强化学习的问题，是非常热门的研究领域。 突破性的深度<em>Q网络</em>（Q-network）在雅达利游戏中仅使用视觉输入就击败了人类， 以及 AlphaGo 程序在棋盘游戏围棋中击败了世界冠军，是两个突出强化学习的例子。</p><p>在强化学习问题中，智能体（agent）在一系列的时间步骤上与环境交互。 在每个特定时间点，智能体从环境接收一些<em>观察</em>（observation），并且必须选择一个<em>动作</em>（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后智能体从环境中获得<em>奖励</em>（reward）。</p><p><img src="2024-03-17-DeepLearning.assets/reinforcementLearning.png" alt="reinforcementLearning"></p><p>强化学习的目标是产生一个好的<em>策略</em>（policy）。 强化学习智能体选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。</p><p>强化学习者必须处理<em>学分分配</em>（credit assignment）问题：决定哪些行为是值得奖励的，哪些行为是需要惩罚的。 </p><p>当环境可被完全观察到时，强化学习问题被称为<em>马尔可夫决策过程</em>（markov decision process）。 当状态不依赖于之前的操作时，我们称该问题为<em>上下文赌博机</em>（contextual bandit problem）。 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的<em>多臂赌博机</em>（multi-armed bandit problem）。</p><p><strong>神经网络（neural networks）</strong></p><ul><li>线性和非线性处理单元的交替，通常称为<em>层</em>（layers）；</li><li>使用链式规则（也称为<em>反向传播</em>（backpropagation））一次性调整网络中的全部参数。</li></ul><h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><h4 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h4><p>为了能够完成各种数据操作，我们需要某种方法来存储和操作数据。 通常，我们需要做两件重要的事：（1）获取数据；（2）将数据读入计算机后对其进行处理。 如果没有某种方法来存储数据，那么获取数据是没有意义的。</p><p>n维数组: <strong>张量</strong>，无论使用哪个深度学习框架，它的<em>张量类</em>（在MXNet中为<code>ndarray</code>， 在PyTorch和TensorFlow中为<code>Tensor</code>）都与Numpy的<code>ndarray</code>类似。 但深度学习框架又比Numpy的<code>ndarray</code>多一些重要功能： 首先，GPU很好地支持加速计算，而NumPy仅支持CPU计算； 其次，张量类支持自动微分。 这些功能使得张量类更适合深度学习。 </p><h5 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h5><p>首先，我们导入<code>torch</code>。请注意，虽然它被称为PyTorch，但是代码中使用<code>torch</code>而不是<code>pytorch</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br></pre></td></tr></table></figure><p>张量表示一个由数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的<em>向量</em>（vector）； 具有两个轴的张量对应数学上的<em>矩阵</em>（matrix）； 具有两个轴以上的张量没有特殊的数学名称。</p><p>首先，我们可以使用 <code>arange</code> 创建一个行向量 <code>x</code>。这个行向量包含以0开始的前12个整数，它们默认创建为整数。也可指定创建类型为浮点数。张量中的每个值都称为张量的 <em>元素</em>（element）。例如，张量 <code>x</code> 中有 12 个元素。除非额外指定，新的张量将存储在内存中，并采用基于CPU的计算。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.arange(12)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])</span><br></pre></td></tr></table></figure><p>可以通过张量的<code>shape</code>属性来访问张量（沿每个轴的长度）的<em>形状</em> 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([12])</span><br></pre></td></tr></table></figure><p>如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。 因为这里在处理的是一个向量，所以它的<code>shape</code>与它的<code>size</code>相同。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.numel()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">12</span><br></pre></td></tr></table></figure><p>要想改变一个张量的形状而不改变元素数量和元素值，可以调用<code>reshape</code>函数。 例如，可以把张量<code>x</code>从形状为（12,）的行向量转换为形状为（3,4）的矩阵。 这个新的张量包含与转换前相同的值，但是它被看成一个3行4列的矩阵。 要重点说明一下，虽然张量的形状发生了改变，但其元素值并没有变。 注意，通过改变张量的形状，张量的大小不会改变。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X &#x3D; x.reshape(3, 4)</span><br><span class="line">X</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0,  1,  2,  3],</span><br><span class="line">        [ 4,  5,  6,  7],</span><br><span class="line">        [ 8,  9, 10, 11]])</span><br></pre></td></tr></table></figure><p>我们不需要通过手动指定每个维度来改变形状。 也就是说，如果我们的目标形状是（高度,宽度）， 那么在知道宽度后，高度会被自动计算得出，不必我们自己做除法。 在上面的例子中，为了获得一个3行的矩阵，我们手动指定了它有3行和4列。 幸运的是，我们可以通过<code>-1</code>来调用此自动计算出维度的功能。 即我们可以用<code>x.reshape(-1,4)</code>或<code>x.reshape(3,-1)</code>来取代<code>x.reshape(3,4)</code>。</p><p>有时，我们希望使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵。 我们可以创建一个形状为（2,3,4）的张量，其中所有元素都设置为0。代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.zeros((2, 3, 4))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[0., 0., 0., 0.],</span><br><span class="line">         [0., 0., 0., 0.],</span><br><span class="line">         [0., 0., 0., 0.]],</span><br><span class="line"></span><br><span class="line">        [[0., 0., 0., 0.],</span><br><span class="line">         [0., 0., 0., 0.],</span><br><span class="line">         [0., 0., 0., 0.]]])</span><br></pre></td></tr></table></figure><p>同样，我们可以创建一个形状为<code>(2,3,4)</code>的张量，其中所有元素都设置为1。代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ones((2, 3, 4))</span><br></pre></td></tr></table></figure><p>有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。 例如，当我们构造数组来作为神经网络中的参数时，我们通常会随机初始化参数的值。 以下代码创建一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randn(3, 4)</span><br></pre></td></tr></table></figure><p>我们还可以通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。 在这里，最外层的列表对应于轴0，内层的列表对应于轴1。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])</span><br></pre></td></tr></table></figure><h5 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x &#x3D; torch.tensor([1.0, 2, 4, 8])</span><br><span class="line">y &#x3D; torch.tensor([2, 2, 2, 2])</span><br><span class="line">x + y, x - y, x * y, x &#x2F; y, x ** y  # **运算符是求幂运算</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([ 3.,  4.,  6., 10.]),</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(tensor([ 3.,  4.,  6., 10.]),</span><br><span class="line"> tensor([-1.,  0.,  2.,  6.]),</span><br><span class="line"> tensor([ 2.,  4.,  8., 16.]),</span><br><span class="line"> tensor([0.5000, 1.0000, 2.0000, 4.0000]),</span><br><span class="line"> tensor([ 1.,  4., 16., 64.]))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(x)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])</span><br></pre></td></tr></table></figure><p>我们也可以把多个张量<em>连结</em>（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。 我们只需要提供张量列表，并给出沿哪个轴连结。 下面的例子分别演示了当我们沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵时，会发生什么情况。 我们可以看到，第一个输出张量的轴-0长度（6）是两个输入张量轴-0长度的总和（3+3）； 第二个输出张量的轴-1长度（8）是两个输入张量轴-1长度的总和（4+4）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X &#x3D; torch.arange(12, dtype&#x3D;torch.float32).reshape((3,4))</span><br><span class="line">Y &#x3D; torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])</span><br><span class="line">torch.cat((X, Y), dim&#x3D;0), torch.cat((X, Y), dim&#x3D;1)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[ 0.,  1.,  2.,  3.],</span><br><span class="line">         [ 4.,  5.,  6.,  7.],</span><br><span class="line">         [ 8.,  9., 10., 11.],</span><br><span class="line">         [ 2.,  1.,  4.,  3.],</span><br><span class="line">         [ 1.,  2.,  3.,  4.],</span><br><span class="line">         [ 4.,  3.,  2.,  1.]]),</span><br><span class="line"> tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],</span><br><span class="line">         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],</span><br><span class="line">         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))</span><br></pre></td></tr></table></figure><h5 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h5><p>在上面的部分中，我们看到了如何在相同形状的两个张量上执行按元素操作。 在某些情况下，即使形状不同，我们仍然可以通过调用 <em>广播机制</em>（broadcasting mechanism）来执行按元素操作。 这种机制的工作方式如下：</p><ul><li>通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；</li><li>对生成的数组执行按元素操作。</li></ul><p>在大多数情况下，我们将沿着数组中长度为1的轴进行广播，如下例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; torch.arange(3).reshape((3, 1))</span><br><span class="line">b &#x3D; torch.arange(2).reshape((1, 2))</span><br><span class="line">a, b</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(tensor([[0],</span><br><span class="line">         [1],</span><br><span class="line">         [2]]),</span><br><span class="line"> tensor([[0, 1]]))</span><br></pre></td></tr></table></figure><p>由于<code>a</code>和<code>b</code>分别是3×1和1×2矩阵，如果让它们相加，它们的形状不匹配。 我们将两个矩阵<em>广播</em>为一个更大的3×2矩阵，如下所示：矩阵<code>a</code>将复制列， 矩阵<code>b</code>将复制行，然后再按元素相加。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a + b</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 1],</span><br><span class="line">        [1, 2],</span><br><span class="line">        [2, 3]])</span><br></pre></td></tr></table></figure><h5 id="索引和切片"><a href="#索引和切片" class="headerlink" title="索引和切片"></a>索引和切片</h5><p>就像在任何其他Python数组中一样，张量中的元素可以通过索引访问。 与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是-1； 可以指定范围以包含第一个元素和最后一个之前的元素。</p><p>如下所示，我们可以用<code>[-1]</code>选择最后一个元素，可以用<code>[1:3]</code>选择第二个和第三个元素：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[-1], X[1:3]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(tensor([ 8.,  9., 10., 11.]),</span><br><span class="line"> tensor([[ 4.,  5.,  6.,  7.],</span><br><span class="line">         [ 8.,  9., 10., 11.]]))</span><br></pre></td></tr></table></figure><p>除读取外，我们还可以通过指定索引来将元素写入矩阵。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ 0.,  1.,  2.,  3.],</span><br><span class="line">       [ 4.,  5.,  9.,  7.],</span><br><span class="line">       [ 8.,  9., 10., 11.]])</span><br></pre></td></tr></table></figure><p>如果我们想为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值。 例如，<code>[0:2, :]</code>访问第1行和第2行，其中“:”代表沿轴1（列）的所有元素。 虽然我们讨论的是矩阵的索引，但这也适用于向量和超过2个维度的张量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X[0:2, :] &#x3D; 12</span><br><span class="line">X</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[12., 12., 12., 12.],</span><br><span class="line">       [12., 12., 12., 12.],</span><br><span class="line">       [ 8.,  9., 10., 11.]])</span><br></pre></td></tr></table></figure><h5 id="节省内存"><a href="#节省内存" class="headerlink" title="节省内存"></a>节省内存</h5><p>运行一些操作可能会导致为新结果分配内存。 例如，如果我们用<code>Y = X + Y</code>，我们将取消引用<code>Y</code>指向的张量，而是指向新分配的内存处的张量。</p><p>在下面的例子中，我们用Python的<code>id()</code>函数演示了这一点， 它给我们提供了内存中引用对象的确切地址。 运行<code>Y = Y + X</code>后，我们会发现<code>id(Y)</code>指向另一个位置。 这是因为Python首先计算<code>Y + X</code>，为结果分配新的内存，然后使<code>Y</code>指向内存中的这个新位置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before &#x3D; id(Y)</span><br><span class="line">Y &#x3D; Y + X</span><br><span class="line">id(Y) &#x3D;&#x3D; before</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False</span><br></pre></td></tr></table></figure><p>这可能是不可取的，原因有两个：</p><ul><li>首先，我们不想总是不必要地分配内存。在机器学习中，我们可能有数百兆的参数，并且在一秒内多次更新所有参数。通常情况下，我们希望原地执行这些更新；</li><li>如果我们不原地更新，其他引用仍然会指向旧的内存位置，这样我们的某些代码可能会无意中引用旧的参数。</li></ul><p>幸运的是，执行原地操作非常简单。 我们可以使用切片表示法将操作的结果分配给先前分配的数组，例如<code>Y[:] = &lt;expression&gt;</code>。 为了说明这一点，我们首先创建一个新的矩阵<code>Z</code>，其形状与另一个<code>Y</code>相同， 使用<code>zeros_like</code>来分配一个全0的块。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Z &#x3D; torch.zeros_like(Y)</span><br><span class="line">print(&#39;id(Z):&#39;, id(Z))</span><br><span class="line">Z[:] &#x3D; X + Y</span><br><span class="line">print(&#39;id(Z):&#39;, id(Z))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">id(Z): 140327634811696</span><br><span class="line">id(Z): 140327634811696</span><br></pre></td></tr></table></figure><p>如果在后续计算中没有重复使用<code>X</code>， 我们也可以使用<code>X[:] = X + Y</code>或<code>X += Y</code>来减少操作的内存开销。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">before &#x3D; id(X)</span><br><span class="line">X +&#x3D; Y</span><br><span class="line">id(X) &#x3D;&#x3D; before</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">True</span><br></pre></td></tr></table></figure><h5 id="转换为其他Python对象"><a href="#转换为其他Python对象" class="headerlink" title="转换为其他Python对象"></a>转换为其他Python对象</h5><p>将深度学习框架定义的张量转换为NumPy张量（<code>ndarray</code>）很容易，反之也同样容易。 torch张量和numpy数组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A &#x3D; X.numpy()</span><br><span class="line">B &#x3D; torch.tensor(A)</span><br><span class="line">type(A), type(B)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(numpy.ndarray, torch.Tensor)</span><br></pre></td></tr></table></figure><p>要将大小为1的张量转换为Python标量，我们可以调用<code>item</code>函数或Python的内置函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a &#x3D; torch.tensor([3.5])</span><br><span class="line">a, a.item(), float(a), int(a)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(tensor([3.5000]), 3.5, 3.5, 3)</span><br></pre></td></tr></table></figure><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><h5 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h5><h4 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h4><h5 id="Basic-function"><a href="#Basic-function" class="headerlink" title="Basic function:"></a>Basic function:</h5><script type="math/tex; mode=display">w,x \in R^{n_x},x= \begin{pmatrix} x_1\\ x_2\\ x_3\\ ...\\ x_{n_x}\end{pmatrix}, b \in R, \\ \hat y= \sigma(w^Tx+b),\hat y \in (0,1),\\ \sigma(z)=\frac{1}{1+e^{-z}} \\</script><h5 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function:"></a>Loss function:</h5><script type="math/tex; mode=display">L(\hat y, y)=-[ y\log \hat y +( 1-y ) \log (1-\hat y)]</script><h5 id="Cost-function"><a href="#Cost-function" class="headerlink" title="Cost function"></a>Cost function</h5><script type="math/tex; mode=display">J(w,b)=\frac{1}{m}\sum _{i=1}^{m}L(\hat y^{(i)}, y^{(i)})</script><h4 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h4><script type="math/tex; mode=display">w:=w-\alpha \frac{dJ(w)}{dw}\\\alpha为learning Rate</script><h4 id="Forward-Propagation"><a href="#Forward-Propagation" class="headerlink" title="Forward Propagation"></a>Forward Propagation</h4><script type="math/tex; mode=display">J(a,b,c)=3(a+bc)\\ u=bc\\v=a+u\\J=3v</script><h4 id="Backward-Propagation"><a href="#Backward-Propagation" class="headerlink" title="Backward Propagation"></a>Backward Propagation</h4><script type="math/tex; mode=display">\frac{dL}{d\hat y}=-\frac{y}{\hat y}+\frac{1-y}{1-\hat y}\\\hat y=\sigma (z)\\\frac{d\hat y}{dz}=\hat y(1-\hat y)\\\frac{dL}{dz}=\frac{dL}{d\hat y}\frac{d\hat y}{dz}=\hat y-y\\\frac{dL}{dw}=\frac{dL}{dz}\frac{dz}{dw}=(\hat y-y)x\\\frac{dL}{db}=\hat y-y</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def propagate(w, b, x, y):</span><br><span class="line">    m &#x3D; x.shape[1]</span><br><span class="line">    # w : (n * 1) x : (n * m) y : (1 * m)</span><br><span class="line">    z &#x3D; np.dot(w.T, x) + b</span><br><span class="line">    a &#x3D; sigmoid(z)</span><br><span class="line">    dw &#x3D; 1.0 &#x2F; m * np.dot(x, (a - y).T)</span><br><span class="line">    db &#x3D; 1.0 &#x2F; m * np.sum(a - y)</span><br><span class="line">    cost &#x3D; -1.0 &#x2F; m * np.sum(y * np.log(a) + (1 - y) * np.log(1 - a))</span><br><span class="line">    grads &#x3D; &#123;&quot;dw&quot;: dw,</span><br><span class="line">             &quot;db&quot;: db&#125;</span><br><span class="line">    return grads, cost</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost &#x3D; False):</span><br><span class="line">    costs &#x3D; []</span><br><span class="line">    for i in range(num_iterations):</span><br><span class="line">        grad, cost &#x3D; propagate(w, b, X, Y)</span><br><span class="line">        dw &#x3D; grad[&quot;dw&quot;]</span><br><span class="line">        db &#x3D; grad[&quot;db&quot;]</span><br><span class="line">        w &#x3D; w - learning_rate * dw</span><br><span class="line">        b &#x3D; b - learning_rate * db</span><br><span class="line">        if i % 100 &#x3D;&#x3D; 0:</span><br><span class="line">            costs.append(cost)</span><br><span class="line">        if print_cost and i % 100 &#x3D;&#x3D; 0:</span><br><span class="line">            print (&quot;Cost after iteration %i: %f&quot; %(i, cost))</span><br><span class="line">    paras &#x3D; &#123;&quot;w&quot;: w,</span><br><span class="line">             &quot;b&quot;: b&#125;</span><br><span class="line">    grads &#x3D; &#123;&quot;dw&quot;: dw,</span><br><span class="line">             &quot;db&quot;: db&#125;</span><br><span class="line">    return paras, grads, costs</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def predict(w, b, X):</span><br><span class="line">    m &#x3D; X.shape[1]</span><br><span class="line">    Y_prediction &#x3D; np.zeros((1,m))</span><br><span class="line">    w &#x3D; w.reshape(X.shape[0], 1)</span><br><span class="line">    A &#x3D; sigmoid(np.dot(w.T, X) + b)</span><br><span class="line">    for i in range(A.shape[1]):</span><br><span class="line">        if A[0, i] &gt; 0.5:    </span><br><span class="line">            Y_prediction[0, i] &#x3D; 1</span><br><span class="line">        else:</span><br><span class="line">            Y_prediction[0, i] &#x3D; 0</span><br><span class="line">    assert(Y_prediction.shape &#x3D;&#x3D; (1, m))</span><br><span class="line">    return Y_prediction</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> DeepLearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OO-hw3</title>
      <link href="/2024/03/17/BUAA-OO-hw3/"/>
      <url>/2024/03/17/BUAA-OO-hw3/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OO-hw3"><a href="#BUAA-OO-hw3" class="headerlink" title="BUAA-OO-hw3"></a>BUAA-OO-hw3</h3><p>架构图如下:</p><p><img src="/2024/03/17/BUAA-OO-hw3/hw_3.png"></p><h4 id="任务清单"><a href="#任务清单" class="headerlink" title="任务清单"></a>任务清单</h4><ul><li>自定义函数嵌套</li><li>求导</li><li>简化</li></ul><h4 id="求导"><a href="#求导" class="headerlink" title="求导"></a>求导</h4><p>本次迭代增加了求导因子，需要对表达式进行求导运算。解决方案是添加DerivativeFactor，并在Poly中增加deprivePoly()方法，实现加减法连接的式子的求导。在Unit中增加deriveUnit()，实现乘法连接的式子的求导。</p><ul><li><p>DerivativeFactor:</p><p>数学表达式表示:<br>$$<br>dx(Expr)<br>$$</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public class DerivativeFactor implements Factor &#123;</span><br><span class="line">    private final Expr expr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>deprivePoly():</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public Poly derivePoly() &#123;</span><br><span class="line">        Poly derivative &#x3D; new Poly();</span><br><span class="line">        for (Unit it : units) &#123;</span><br><span class="line">            derivative.addUnitList(it.deriveUnit());</span><br><span class="line">        &#125;</span><br><span class="line">        return derivative;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>deriveUnit():</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public ArrayList&lt;Unit&gt; deriveUnit() &#123;</span><br><span class="line">        if (exp.equals(BigInteger.ZERO)) &#123;</span><br><span class="line">            return expZero();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return expNotZero();</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="自定义函数嵌套"><a href="#自定义函数嵌套" class="headerlink" title="自定义函数嵌套"></a>自定义函数嵌套</h4><p>解决方案是在FuncAnalysis类中的转换函数中进行递归调用，直至消除所有函数，得到最终的表达式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">while (real.contains(&quot;h&quot;) || real.contains(&quot;g&quot;) || real.contains(&quot;f&quot;)) &#123;</span><br><span class="line">            Lexer lexer &#x3D; new Lexer(real);</span><br><span class="line">            Parser parser &#x3D; new Parser(lexer);</span><br><span class="line">            Expr expr &#x3D; parser.parserExpr();</span><br><span class="line">            real &#x3D; expr.toPoly().toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="简化"><a href="#简化" class="headerlink" title="简化"></a>简化</h4><p>这一步大概是整个项目中最繁琐的，我将其分为三种情况:</p><ul><li><p>系数等于1:</p><p>只需要输出形如 $ x*exp() $ 的字符串。</p></li><li><p>系数等于-1:</p><p>只需要输出形如 $ -x*exp() $ 的字符串。</p></li><li><p>其他情况:</p><p>输出形如 $ coe * x * exp() $ 的字符串。</p></li></ul><p>在每一种情况下，需要对exp()内部的Poly进行提取最大公因数的操作，即在Poly中增加getGcd()方法，返回一个Hashmap，包含最大公因数和提取完成后的表达式。实现：$ \exp((2 * x-100 * x^2)) $  转变为  $ \exp((x-50 * x^2)^2 $。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public HashMap&lt;BigInteger, Poly&gt; getGcd() &#123;</span><br><span class="line">        Poly poly &#x3D; this.clone();</span><br><span class="line">        ArrayList&lt;BigInteger&gt; numbers &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">        for (Unit it : poly.units) &#123;</span><br><span class="line">            if (!it.getCoe().equals(BigInteger.ZERO)) &#123;</span><br><span class="line">                numbers.add(it.getCoe()); &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        BigInteger gcd &#x3D; findGcd(numbers);</span><br><span class="line">        for (Unit it : poly.units) &#123;</span><br><span class="line">            BigInteger temp &#x3D; it.getCoe().divide(gcd);</span><br><span class="line">            it.setCoe(temp);</span><br><span class="line">        &#125;</span><br><span class="line">        HashMap&lt;BigInteger, Poly&gt; hash &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">        hash.put(gcd, poly);</span><br><span class="line">        return hash;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>本次迭代难度不大，主要是简化部分太过繁琐，需要耗费一点时间。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OO-hw2</title>
      <link href="/2024/03/17/BUAA-OO-hw2/"/>
      <url>/2024/03/17/BUAA-OO-hw2/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OO-hw2"><a href="#BUAA-OO-hw2" class="headerlink" title="BUAA-OO-hw2"></a>BUAA-OO-hw2</h3><p>架构图如下:</p><p><img src="hw_2.png" alt=""></p><h4 id="任务清单"><a href="#任务清单" class="headerlink" title="任务清单"></a>任务清单</h4><p>增加了exp()因子，新增自定义函数因子。</p><h4 id="重构"><a href="#重构" class="headerlink" title="重构"></a>重构</h4><p>本次作业并不适用于第一次作业的架构，故选择重构。此次重构增加Unit类和Poly类，以替代Hashmap来进行表达式的计算和简化。</p><h5 id="Unit类"><a href="#Unit类" class="headerlink" title="Unit类:"></a>Unit类:</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public class Unit &#123;</span><br><span class="line">    private BigInteger coe;</span><br><span class="line">    private final BigInteger exp;</span><br><span class="line">    private final Poly expRatio;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>数学公式表示:</p><script type="math/tex; mode=display">a*x^b*exp((\sum_{i=1}^na_i*x_i^b*exp))</script><p>coe为系数，exp为varible的指数，expRatio为exp()因子的表达式因子的Poly形式。</p><h5 id="Poly类"><a href="#Poly类" class="headerlink" title="Poly类:"></a>Poly类:</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public class Poly &#123;</span><br><span class="line">    private ArrayList&lt;Unit&gt; units;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>数学公式表示:</p><script type="math/tex; mode=display">\sum_{i=1}^nUnit_i</script><p>用ArrayList存储各个unit，最后用toString()方法输出最终表达式。</p><h4 id="自定义函数处理"><a href="#自定义函数处理" class="headerlink" title="自定义函数处理"></a>自定义函数处理</h4><p>专门新建一个FunctAnalysis类用于对函数表达式的处理和转换。处理主要是提取出函数名和表达式，转换是将待处理的带函数的表达式转换为无函数表达式。</p><h5 id="FunctAnalysis"><a href="#FunctAnalysis" class="headerlink" title="FunctAnalysis"></a>FunctAnalysis</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public class FuncAnalysis &#123;</span><br><span class="line">    private static HashMap&lt;String, String&gt; funcMap &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">    private static HashMap&lt;String, ArrayList&lt;String&gt;&gt; parametric &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>funcMap: 用于对函数名和函数表达式的映射。</li><li>parametric: 用于函数名对于函数的未知变量的映射。</li></ul><h5 id="FuncFactor"><a href="#FuncFactor" class="headerlink" title="FuncFactor"></a>FuncFactor</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public class FuncFactor implements Factor &#123;</span><br><span class="line">    private final String result;</span><br><span class="line">    private final Expr expr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>result: 经过FunctAnalysis转换后的表达式字符串。</li><li>expr: 将result转换为Expr类的形式。</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>本次作业对上次作业进行重构，构建了可拓展性更好的架构。缺点在于没有对表达式进行化简，在后续迭代中需要进一步补充。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OS-Lab1</title>
      <link href="/2024/03/15/BUAA-OS-Lab1/"/>
      <url>/2024/03/15/BUAA-OS-Lab1/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OS-Lab1"><a href="#BUAA-OS-Lab1" class="headerlink" title="BUAA_OS_Lab1"></a>BUAA_OS_Lab1</h3><h4 id="一、实验思考题"><a href="#一、实验思考题" class="headerlink" title="一、实验思考题"></a>一、实验思考题</h4><h5 id="Thinking-1-1"><a href="#Thinking-1-1" class="headerlink" title="Thinking 1.1"></a>Thinking 1.1</h5><blockquote><p>请阅读 附录中的编译链接详解，尝试分别使用实验环境中的原生x86 工具 链（gcc、ld、readelf、objdump 等）和 MIPS 交叉编译工具链（带有 mips-linux-gnu-前缀），重复其中的编译和解析过程，观察相应的结果，并解释其中向objdump传入的参数的含义。</p></blockquote><p>执行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -E hello.c</span><br></pre></td></tr></table></figure><p>得到结果：C语言的预处理器将头文件的内容添加到了源文件中</p><p><img src="gcc_E.png" alt=""></p><p>执行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -c hello.c</span><br></pre></td></tr></table></figure><p>得到hello.o文件，在对hello.o文件进行反汇编，导入到obj文件中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objdump -DS hello.o &gt; obj</span><br></pre></td></tr></table></figure><p>obj中main函数部分代码如下所示:</p><p><img src="obj_main.png" alt=""></p><p>执行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc -o hello hello.c</span><br><span class="line">objdump -DS hello &gt; obj_hello</span><br></pre></td></tr></table></figure><p>obj_hello部分结果如图:</p><p><img src="obj_hello.png" alt=""></p><p>objdump传入的第一个参数为需要反编译的文件名, 第二个参数为反编译结果输入到的文件。</p><h5 id="Thinking-1-2"><a href="#Thinking-1-2" class="headerlink" title="Thinking 1.2"></a>Thinking 1.2</h5><blockquote><p>尝试使用我们编写的readelf程序，解析之前在target目录下生成的内核ELF文件。</p><p>也许你会发现我们编写的readelf程序是不能解析readelf文件本身的，而我们刚 才介绍的系统工具readelf则可以解析，这是为什么呢？（提示：尝试使用readelf-h，并阅读tools/readelf目录下的Makefile，观察readelf与hello的不同）</p></blockquote><p>解析结果:</p><p><img src="readelf_hello.png" alt=""></p><p>执行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">readelf -h hello</span><br></pre></td></tr></table></figure><p>结果如图:</p><p><img src="readelf_hello1.png" alt=""></p><p>执行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">readelf -h .&#x2F;readelf</span><br></pre></td></tr></table></figure><p>结果如图:</p><p><img src="readelf_readelf.png" alt=""></p><p>由上可知：hello的文件类型是EXEC(可执行文件)，而readelf的文件类型是DYN(地址独立的可执行文件)，readelf程序本身只能解析可执行文件，所以解析不了readelf文件本身，而系统工具readelf可以解析所有可执行文件，所以可以解析./readelf。</p><h5 id="Thinking-1-3"><a href="#Thinking-1-3" class="headerlink" title="Thinking 1.3"></a>Thinking 1.3</h5><blockquote><p>在理论课上我们了解到，MIPS体系结构上电时，启动入口地址为0xBFC00000 （其实启动入口地址是根据具体型号而定的，由硬件逻辑确定，也有可能不是这个地址，但 一定是一个确定的地址），但实验操作系统的内核入口并没有放在上电启动地址，而是按照内存布局图放置。思考为什么这样放置内核还能保证内核入口被正确跳转到？ （提示：思考实验中启动过程的两阶段分别由谁执行。）</p></blockquote><p>因为引导加载程序在初始化虚拟内存系统时，会将内核映像加载到虚拟地址空间的某个位置，并设置相应的页表条目。这样，CPU就可以通过虚拟地址访问内核，之后会执行一个跳转指令，将控制权交给内核的入口点。</p><h4 id="二、实验难点"><a href="#二、实验难点" class="headerlink" title="二、实验难点"></a>二、实验难点</h4><h5 id="readelf-c文件编写"><a href="#readelf-c文件编写" class="headerlink" title="readelf.c文件编写"></a>readelf.c文件编写</h5><p>需要通过教程中的结构体数据类型和变量定义，查表得到节头表的地址、节头数量和大小。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sh_table &#x3D; (const void *)((char *)binary + ehdr-&gt;e_shoff);</span><br><span class="line">sh_entry_count &#x3D; ehdr-&gt;e_shnum;</span><br><span class="line">sh_entry_size &#x3D; ehdr-&gt;e_shentsize;</span><br></pre></td></tr></table></figure><p>要获得每个节头的地址需要用节头表指针加上index与节头大小的乘积。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shdr &#x3D; (Elf32_Shdr *)((char *)sh_table + (i * sh_entry_size));</span><br></pre></td></tr></table></figure><h5 id="补全kernel-lds文件"><a href="#补全kernel-lds文件" class="headerlink" title="补全kernel.lds文件"></a>补全kernel.lds文件</h5><p>根据教程格式写即可，注意内核的位置。</p><h5 id="init-start-S文件补全"><a href="#init-start-S文件补全" class="headerlink" title="init/start.S文件补全"></a>init/start.S文件补全</h5><p>将栈指针指向kernelbase，跳转到mips_init函数即可。</p><h5 id="完成vprintfmt-函数"><a href="#完成vprintfmt-函数" class="headerlink" title="完成vprintfmt()函数"></a>完成vprintfmt()函数</h5><p>由于vprintfmt()函数的实现方法有很多种，所以在完成这一部分时可以不按照教程代码注释的指引来写。需要注意的是循环的break条件，遇见’\0’需要跳出循环，不然会陷入死循环。还需要注意实现解析各个符号的含义，按照教程来即可。</p><h4 id="三、实验体会"><a href="#三、实验体会" class="headerlink" title="三、实验体会"></a>三、实验体会</h4><p>本次实验总体而言难度不大，但由于教程写的比较难懂，所以需要多耗费一些时间在教程的阅读和理解上面。同时也需要注意一些细节，容易在细节上出错。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA_OO_hw1</title>
      <link href="/2024/03/11/BUAA-OO-hw1/"/>
      <url>/2024/03/11/BUAA-OO-hw1/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OO-hw1"><a href="#BUAA-OO-hw1" class="headerlink" title="BUAA_OO_hw1"></a>BUAA_OO_hw1</h3><p>架构图如下：</p><p><img src="hw_1.png" alt=""></p><h4 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h4><p>创建Processor类对输入的表达式进行预处理，去除空格、合并符号、将乘方拆分为多个x相乘的形式(例如：<em>x^3</em>  → x <em> x </em> x)</p><h4 id="expr包设计"><a href="#expr包设计" class="headerlink" title="expr包设计"></a>expr包设计</h4><p><img src="expr.png" alt=""></p><h5 id="Factor"><a href="#Factor" class="headerlink" title="Factor"></a>Factor</h5><p>本次作业因子分为两种: Number和Varible。为了方便后续的表达式运算，我根据因子计算的性质在其中设计了一个Hashmap来存储其指数和系数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class Number &#123;</span><br><span class="line">    </span><br><span class="line">    private HashMap&lt;Integer, BigInteger&gt; map &#x3D; new HashMap&lt;&gt;();</span><br><span class="line">    </span><br><span class="line">    public HashMap&lt;Integer, BigInteger&gt; getMap() &#123;</span><br><span class="line">        return map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public class Var &#123;</span><br><span class="line"></span><br><span class="line">    private final HashMap&lt;Integer, BigInteger&gt; map &#x3D; new HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    public HashMap&lt;Integer, BigInteger&gt; getMap() &#123;</span><br><span class="line">        return map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="Term"><a href="#Term" class="headerlink" title="Term"></a>Term</h5><p>Term由Factor相乘得到，因此也使用Hashmap存储其指数和系数，同时为了乘法计算，使用mergeFactor()方法对Factor的乘法运算进行处理。</p><p>形式:</p><script type="math/tex; mode=display">a*x^b</script><h5 id="Expr"><a href="#Expr" class="headerlink" title="Expr"></a>Expr</h5><p>Expr由Term相加得到，也使用Hashmap存储每个Term的指数和系数，增加mergeTerm()方法对Term的加法进行处理。</p><p>形式:</p><script type="math/tex; mode=display">\sum_{i=1}^na_i*x_i^b</script><h4 id="递归下降"><a href="#递归下降" class="headerlink" title="递归下降"></a>递归下降</h4><p>按照训练给出的架构来做就好了：</p><h5 id="Lexer"><a href="#Lexer" class="headerlink" title="Lexer"></a>Lexer</h5><p>将processor处理后的表达式输入到Lexer中，Lexer通过next()方法解析表达式，再通过peek()方法将解析出的”词”传入Parser中。</p><h5 id="Parser"><a href="#Parser" class="headerlink" title="Parser"></a>Parser</h5><p>对Lexer传出的curToken在进行分析，运用parseExpr()方法获得Expr、parseTerm()获得Term、parseFactor()获得Factor。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>由于本次作业表达式形式相对简单，所以我也采用了Hashmap这种简单的方法进行处理。好处就是加减乘除计算处理非常简单，不需要递归。坏处就是可拓展性极差，只适用于第一次作业这种特定形式的表达式，因此在后续迭代中需要进行重构。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA_OS_Lab0</title>
      <link href="/2024/03/11/BUAA-OS-Lab0/"/>
      <url>/2024/03/11/BUAA-OS-Lab0/</url>
      
        <content type="html"><![CDATA[<h3 id="BUAA-OS-Lab0"><a href="#BUAA-OS-Lab0" class="headerlink" title="BUAA_OS_Lab0"></a>BUAA_OS_Lab0</h3><h4 id="一、实验思考题"><a href="#一、实验思考题" class="headerlink" title="一、实验思考题"></a>一、实验思考题</h4><h5 id="Thinking-0-1"><a href="#Thinking-0-1" class="headerlink" title="Thinking 0.1"></a>Thinking 0.1</h5><ul><li><p>执行cat Untracked.txt后的结果：README.txt文件位于untracked区</p><p><img src="/2024/03/11/BUAA-OS-Lab0/cat_Untracked.png" alt="cat_untracked"></p></li><li><p>执行cat Stage.txt后的结果：README.txt文件位于staged区</p><p><img src="/2024/03/11/BUAA-OS-Lab0/cat_stage.png"></p></li><li><p>修改修改README.txt 文件，再执行命令git status &gt; Modified.txt。执行命令cat Modified.txt后的结果：</p><p><img src="/2024/03/11/BUAA-OS-Lab0/modified.png"></p></li></ul><p>结果和第一次执行 add 命令之前的 status 不一样。第一次执行 add 命令之前的README.txt的 status是未跟踪，修改后的status是未暂存以备提交的变更</p><p>原因是执行add命令前README.txt未被跟踪，后续执行add命令文件被跟踪修改后未提交，所以处于未暂存状态。</p><h5 id="Thinking-0-2"><a href="#Thinking-0-2" class="headerlink" title="Thinking 0.2"></a>Thinking 0.2</h5><blockquote><p>Thinking0.2 仔细看看0.10，思考一下箭头中的add thefile、stage thefile和 commit分别对应的是Git里的哪些命令呢？</p></blockquote><p><img src="/2024/03/11/BUAA-OS-Lab0/status.png"></p><p>add the file 对应指令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add</span><br></pre></td></tr></table></figure><p>stage the file 对应指令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add</span><br></pre></td></tr></table></figure><p>commit 对应指令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit</span><br></pre></td></tr></table></figure><h5 id="Thinking-0-3"><a href="#Thinking-0-3" class="headerlink" title="Thinking 0.3"></a>Thinking 0.3</h5><p><img src="/2024/03/11/BUAA-OS-Lab0/git_structure.png"></p><blockquote><p>1、代码文件print.c 被错误删除时，应当使用什么命令将其恢复？</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -- print.c</span><br></pre></td></tr></table></figure><blockquote><p>2、代码文件 print.c 被错误删除后，执行了 git rm print.c 命令，此时应当 使用什么命令将其恢复？</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout HEAD print.c</span><br></pre></td></tr></table></figure><blockquote><p>3、无关文件 hello.txt 已经被添加到暂存区时，如何在不删除此文件的前提下将其移出暂存区？</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset HEAD hello.txt</span><br></pre></td></tr></table></figure><h5 id="Thinking-0-4"><a href="#Thinking-0-4" class="headerlink" title="Thinking 0.4"></a>Thinking 0.4</h5><ul><li><p>在文件里加入Testing 1，git add，git commit，提交说明记为1。模仿上述做法，把1分别改为2和3，再提交两次。<img src="/2024/03/11/BUAA-OS-Lab0/4_add.png"></p></li><li><p>使用git log命令查看提交日志，看是否已经有三次提交，记下提交说明为3的哈希值。</p><p><img src="/2024/03/11/BUAA-OS-Lab0/log_1.png"></p></li><li><p>进行版本回退。执行命令git reset –hard HEAD^后，再执行git log，观 察其变化。</p><p><img src="/2024/03/11/BUAA-OS-Lab0/log_2.png"></p></li><li><p>找到提交说明为1的哈希值，执行命令git reset –hard后，再执 行git log，观察其变化。</p><p><img src="/2024/03/11/BUAA-OS-Lab0/log_3.png"></p></li><li><p>现在已经回到了旧版本，为了再次回到新版本，执行git reset –hard ，再执行git log，观察其变化。</p><p><img src="/2024/03/11/BUAA-OS-Lab0/log_4.png"></p></li></ul><h5 id="Thinking-0-5"><a href="#Thinking-0-5" class="headerlink" title="Thinking 0.5"></a>Thinking 0.5</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo first</span><br></pre></td></tr></table></figure><p><img src="/2024/03/11/BUAA-OS-Lab0/echo_1.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo second &gt; output.txt</span><br></pre></td></tr></table></figure><p><img src="/2024/03/11/BUAA-OS-Lab0/echo_2.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo third &gt; output.txt</span><br></pre></td></tr></table></figure><p><img src="/2024/03/11/BUAA-OS-Lab0/echo_3.png"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo forth &gt;&gt; output.txt</span><br></pre></td></tr></table></figure><p><img src="/2024/03/11/BUAA-OS-Lab0/echo_4.png"></p><h5 id="Thinking-0-6"><a href="#Thinking-0-6" class="headerlink" title="Thinking 0.6"></a>Thinking 0.6</h5><p>command文件内容：</p><p><img src="/2024/03/11/BUAA-OS-Lab0/command.png"></p><p>result文件内容：</p><p><img src="/2024/03/11/BUAA-OS-Lab0/result.png"></p><p>test文件命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo ...</span><br></pre></td></tr></table></figure><p>将…中的内容输出到result中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a&#x3D;1</span><br><span class="line">b&#x3D;2</span><br><span class="line">c&#x3D;$[$a+$b]</span><br></pre></td></tr></table></figure><p>将a赋值为1，b赋值为2，c赋值为3</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo $c&gt;file1</span><br><span class="line">echo $b&gt;file2</span><br><span class="line">echo $a&gt;file3</span><br></pre></td></tr></table></figure><p>将a输出到为file3，c输出到为file1，b输出到为file2</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat file1&gt;file4</span><br><span class="line">cat file2&gt;&gt;file4</span><br><span class="line">cat file3&gt;&gt;file4</span><br><span class="line">cat file4&gt;&gt;result</span><br></pre></td></tr></table></figure><p>将file1 file2 file3的值依次输出到file4中，再将file4的值输出到result尾部。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo echo Shell Start</span><br><span class="line">echo &#39;echo Shell Start&#39;</span><br></pre></td></tr></table></figure><p>效果无区别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo echo $c&gt;file1</span><br><span class="line">echo ’echo $c&gt;file1‘</span><br></pre></td></tr></table></figure><p>效果有区别，上面的输出结果为echo，下面输出结果为echo $c&gt;file1</p><h4 id="二、实验难点分析"><a href="#二、实验难点分析" class="headerlink" title="二、实验难点分析"></a>二、实验难点分析</h4><h5 id="bash脚本编写"><a href="#bash脚本编写" class="headerlink" title="bash脚本编写"></a>bash脚本编写</h5><p>[sed指令的使用]</p><blockquote><p>在src&#x2F;sh_test 目录下，有一个file 文件和hello_os.sh 文件。hello_os.sh 是 一个未完成的脚本文档，请同学们借助shell编程的知识，将其补完，以实现通过命令bash hello_os.sh AAA BBB，在 hello_os.sh 所处的目录新建一个名为 BBB 的文件，其内容为AAA文件的第8、32、128、512、1024行的内容提取(AAA文件行数一定超过1024行)。[注 意：对于命令bashhello_os.sh AAABBB，AAA及BBB可为任何合法文件的名称，例如 bashhello_os.sh filehello_os.c，若已有hello_os.c文件，则将其原有内容覆盖]</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">sed -n &#39;8p, 32p, 128p, 512p, 1024p&#39; $1 &gt; $2</span><br></pre></td></tr></table></figure><p>使用sed指令将参数$1文件中指定行输出到$2中</p><blockquote><p>在Lab0工作区的csc&#x2F;code目录下，存在fibo.c、main.c，其中fibo.c有点小 问题，还有一个未补全的modify.sh文件，将其补完，以实现通过命令bash modify.sh fibo.c char int，可以将fibo.c中所有的char字符串更改为int字符串。[注意：对于 命令bashmodify.sh fibo.ccharint，fibo.c可为任何合法文件名，char及int可 以是任何字符串，评测时评测modify.sh的正确性，而不是检查修改后fibo.c的正确性]</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">sed -i &quot;s&#x2F;$2&#x2F;$3&#x2F;g&quot; $1</span><br></pre></td></tr></table></figure><p>[循环语句的使用]</p><blockquote><p>在Lab0工作区ray&#x2F;sh_test1目录中，含有100个子目录file1<del>file100，还存 在一个名为changefile.sh的文件，将其补完，以实现通过命令bashchangefile.sh，可 以删除该目录内file71</del>file100共计30个子目录，将file41<del>file70共计30个子目录 重命名为newfile41</del>newfile70。[注意：评测时仅检测changefile.sh的正确性]</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">a&#x3D;1</span><br><span class="line">while [ $a -le 100 ]</span><br><span class="line">do</span><br><span class="line">if [ $a -gt 70 ]</span><br><span class="line">then</span><br><span class="line">rm -r file$a</span><br><span class="line">elif [ $a -gt 40 ]</span><br><span class="line">then</span><br><span class="line">mv file$a newfile$a</span><br><span class="line">fi</span><br><span class="line">a&#x3D;$((a+1))</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>[grep和awk指令的使用 重定向和管道的运用]</p><blockquote><p>在Lab0工作区的ray&#x2F;sh_test2目录下，存在一个未补全的search.sh文件， 将其补完，以实现通过命令bash search.sh file int result，可以在当前目录下生成 result文件，内容为file文件含有int字符串所在的行数，即若有多行含有int字符串 需要全部输出。[注意：对于命令bashsearch.sh file int result，file及result可 为任何合法文件名称，int可为任何合法字符串，若已有result文件，则将其原有内容覆 盖，匹配时大小写不忽略]</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">grep -n $2 $1 | awk -F : &#39;&#123;prin $1&#125;&#39; &gt; $3</span><br></pre></td></tr></table></figure><h5 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h5><blockquote><p>补全后的palindrome.c、Makefile、hello_os.sh依次复制到路径dst&#x2F;palindrome.c, dst&#x2F;Makefile,dst&#x2F;sh_test&#x2F;hello_os.sh[注意：文件名和路径必须与题目要求相同]</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mv palindrome.c ..&#x2F;dst</span><br><span class="line">mv Makefile ..&#x2F;dst</span><br><span class="line">mv hello_os.sh ..&#x2F;dst&#x2F;sh_test</span><br></pre></td></tr></table></figure><h5 id="Makefile编写"><a href="#Makefile编写" class="headerlink" title="Makefile编写"></a>Makefile编写</h5><blockquote><p>Lab0工作区的csc&#x2F;code&#x2F;fibo.c成功更换字段后(bashmodify.shfibo.cchar int)，现已有csc&#x2F;Makefile和csc&#x2F;code&#x2F;Makefile，补全两个Makefile文件，要求在 csc目录下通过命令make可在csc&#x2F;code目录中生成fibo.o、main.o，在csc目录中生 成可执行文件fibo，再输入命令makeclean后只删除两个.o文件。[注意：不能修改 fibo.h和main.c文件中的内容，提交的文件中fibo.c必须是修改后正确的fibo.c，可 执行文件fibo作用是输入一个整数n(从stdin输入n)，可以输出斐波那契数列前n项， 每一项之间用空格分开。比如n&#x3D;5，输出11235]</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">all: fibo                                                            </span><br><span class="line">fibo: code&#x2F;fibo.o code&#x2F;main.o</span><br><span class="line">gcc -o fibo code&#x2F;fibo.o code&#x2F;main.o</span><br><span class="line">code&#x2F;fibo.o: code&#x2F;fibo.c</span><br><span class="line">gcc -c code&#x2F;fibo.c -o code&#x2F;fibo.o -I include</span><br><span class="line">code&#x2F;main.o: code&#x2F;main.c</span><br><span class="line">gcc -c code&#x2F;main.c -o code&#x2F;main.o -I include</span><br><span class="line">clean:</span><br><span class="line">rm -r code&#x2F;main.o code&#x2F;fibo.o</span><br></pre></td></tr></table></figure><h4 id="三、实验体会"><a href="#三、实验体会" class="headerlink" title="三、实验体会"></a>三、实验体会</h4><p>由于上机前没有仔细看教程，导致对Linux一些指令用法的不熟悉、对Makefile和bash脚本写法不熟悉。这也导致了我在上机时写的很慢。在仔细阅读教程后，终于对自己犯的一些错误恍然大悟，对git、Linux命令、bash脚本编写和Makefile编写有了进一步的认识。总体而言，本次实验难度不大，主要是考察我们对基础知识的理解。</p>]]></content>
      
      
      
        <tags>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello world</title>
      <link href="/2024/03/11/Hello-world/"/>
      <url>/2024/03/11/Hello-world/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
